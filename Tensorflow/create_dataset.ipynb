{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ebd193f-304d-4d56-a430-41e2c6a7142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3248c761-2a1a-4953-9a08-81210dc9c63f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import time\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from transformers import AdamW\n",
    "from torch.utils.data import Dataset, IterableDataset\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from vl_Build_model_network import *\n",
    "from transformers import OpenAIGPTTokenizer, OpenAIGPTModel,OpenAIGPTLMHeadModel, AutoModelForCausalLM,AutoTokenizer\n",
    "from vl_model_args import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f97c43df-2008-498b-8681-c998e64c6c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b5f8af13-e46d-4144-b549-c0f40c8f703e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\", cache_dir = 'Model')\n",
    "model = AutoModelForCausalLM.from_pretrained(\"openai-community/gpt2\", cache_dir = 'Model')\n",
    "# pad_token =  '[PAD]'\n",
    "# sep_token =  '[SEP]'\n",
    "# tokenizer.add_special_tokens({'additional_special_tokens': [pad_token]+[sep_token]})\n",
    "# pad_token_id = tokenizer.convert_tokens_to_ids('[PAD]')\n",
    "# sep_token_id = tokenizer.convert_tokens_to_ids('[SEP]')\n",
    "special_tokens = {'pad_token':'<|pad|>','sep_token':'<|sep|>'}\n",
    "num_add_toks = tokenizer.add_special_tokens(special_tokens)\n",
    "# tokenizer.add_special_tokens({'Sep_token': '[SEP]'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e8d8b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e5904d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb809d83-89fb-46f3-a782-44ef4408508a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "902693ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<|endoftext|>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94102c43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2TokenizerFast(name_or_path='openai-community/gpt2', vocab_size=50257, model_max_length=1024, is_fast=True, padding_side='right', truncation_side='right', special_tokens={'bos_token': '<|endoftext|>', 'eos_token': '<|endoftext|>', 'unk_token': '<|endoftext|>', 'sep_token': '<|sep|>', 'pad_token': '<|pad|>'}, clean_up_tokenization_spaces=True),  added_tokens_decoder={\n",
       "\t50256: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=True, special=True),\n",
       "\t50257: AddedToken(\"<|pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "\t50258: AddedToken(\"<|sep|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
       "}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "946a6875-97d1-4bd8-be7e-87b7f961895b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('<|sep|>', {'input_ids': [50258], 'attention_mask': [1]})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.sep_token, tokenizer(tokenizer.sep_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "810f7cb1-841d-43b9-9266-daa90f456fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ignore_idx = tokenizer.pad_token_id\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7ac2c4dd-1efb-49e3-88a5-2bf1bb596fe4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(50259, 768)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "22dc169a-fc46-4f48-8bba-c20f4920eff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(\"Where did fortune cookies originate ?\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7459b336-68b9-40c6-9c11-1e61f061702b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c2bb49-fa41-49d8-93fc-886befafba4b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cdbae76-2ef4-482d-a2a1-f122dfd60ad8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "outputs =  model.generate(input_ids = token['input_ids'], max_new_tokens = 50)\n",
    "out = tokenizer.decode(outputs[0], skip_special_tokens = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c87fc217-aa0f-4547-be53-ec32d4c42fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Where did fortune cookies originate?\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8f0929-8544-40c2-8190-f9657f2991a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a1dde9df-a055-44d3-9877-f7ed1ad0ad56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "<class 'torch.Tensor'> torch.int64\n"
     ]
    }
   ],
   "source": [
    "input_ids = token['input_ids']\n",
    "print(input_ids.size())\n",
    "print(type(input_ids), input_ids.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f34de3af-8e17-4247-bd9e-e0a98bf405ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CausalLMOutputWithCrossAttentions(loss=None, logits=tensor([[[-3.2687e+01, -3.1960e+01, -3.5255e+01,  ..., -3.2099e+01,\n",
       "           4.0421e-01,  4.1818e-01],\n",
       "         [-8.7095e+01, -8.6464e+01, -8.9933e+01,  ..., -8.7396e+01,\n",
       "           2.3679e+00, -1.8623e+00],\n",
       "         [-9.2922e+01, -9.1611e+01, -9.6331e+01,  ..., -9.5655e+01,\n",
       "           2.3855e+00,  7.8973e-01],\n",
       "         [-1.0124e+02, -1.0095e+02, -1.0534e+02,  ..., -1.0455e+02,\n",
       "           2.8520e+00, -1.4060e+00],\n",
       "         [-6.6829e+01, -6.8585e+01, -7.1825e+01,  ..., -7.2043e+01,\n",
       "           2.2912e-01, -1.1065e-02],\n",
       "         [-1.1713e+02, -1.1552e+02, -1.1945e+02,  ..., -1.1490e+02,\n",
       "           2.1203e+00,  2.4318e-01]]], grad_fn=<UnsafeViewBackward0>), past_key_values=((tensor([[[[-1.1705,  1.9088,  0.5898,  ..., -1.4944, -0.6937,  1.4462],\n",
       "          [-1.7728,  1.9535,  2.0315,  ..., -1.1755, -2.4116,  2.5686],\n",
       "          [-1.8935,  1.2292,  1.5397,  ..., -2.6831, -2.0781,  0.5863],\n",
       "          [-1.6944,  3.4057,  0.8116,  ..., -1.4080, -1.4006,  2.5919],\n",
       "          [-0.8691,  1.9563,  1.5153,  ..., -0.6659, -1.5772,  1.6754],\n",
       "          [-2.6769,  2.6748,  2.5483,  ..., -0.4397, -1.9399,  1.8487]],\n",
       "\n",
       "         [[-0.7757, -0.0397,  0.0094,  ..., -0.0375,  2.0016,  0.7157],\n",
       "          [ 1.5294, -1.5553,  0.0134,  ..., -1.4255,  4.2240,  1.3284],\n",
       "          [-1.5719, -1.8649, -1.3373,  ...,  1.0725,  3.5679,  0.9315],\n",
       "          [-1.8144, -1.5410, -0.5685,  ..., -0.0763,  3.2702,  1.6208],\n",
       "          [-0.5981, -0.2125, -0.2361,  ..., -1.3211,  4.2203,  0.6687],\n",
       "          [ 0.2224, -3.0668, -0.9317,  ..., -1.7395,  2.8164, -0.3381]],\n",
       "\n",
       "         [[-0.1103,  0.0403,  0.9990,  ..., -1.4586, -1.8119,  0.5657],\n",
       "          [ 0.2741,  0.3063,  0.3364,  ..., -2.7589,  0.3696,  2.1058],\n",
       "          [ 2.3417,  0.2146,  0.2775,  ..., -2.5802, -0.3055,  0.6427],\n",
       "          [ 1.4686, -0.6766, -2.0538,  ..., -2.6359, -0.5998,  1.5144],\n",
       "          [ 0.3293,  0.4190,  0.1487,  ..., -2.0999,  0.6122,  1.2499],\n",
       "          [ 0.8599, -0.2220,  1.5599,  ..., -1.5502,  1.9315,  2.0410]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.5480, -0.0695, -0.2448,  ...,  0.3349,  0.3604,  0.4062],\n",
       "          [ 0.2000, -0.0866, -0.1658,  ...,  0.7355,  0.3481,  0.3842],\n",
       "          [ 0.0292,  1.1191, -0.6522,  ...,  1.6975,  0.6256,  0.8557],\n",
       "          [-1.2481, -0.4678, -0.4723,  ...,  0.9751,  1.4238, -0.1823],\n",
       "          [ 0.6022, -0.6817,  0.3647,  ...,  1.0762,  0.5981,  0.0487],\n",
       "          [ 0.1636,  0.0515, -0.2559,  ...,  0.9470,  0.6984,  0.0324]],\n",
       "\n",
       "         [[ 1.4845,  1.2995, -0.3334,  ..., -0.1853,  1.2482, -0.9914],\n",
       "          [ 0.6590,  0.7097, -0.8913,  ..., -0.8926,  1.3069, -0.6976],\n",
       "          [ 1.4216,  0.0785, -0.6944,  ..., -0.6207,  1.3094, -1.1034],\n",
       "          [ 0.2200,  0.9984, -0.5833,  ..., -0.1544,  1.3497, -0.4864],\n",
       "          [ 0.1839,  0.4835, -0.4649,  ..., -0.8127,  0.6612, -0.0194],\n",
       "          [ 1.2926, -0.4468, -0.4791,  ..., -0.6221,  1.3971,  0.8326]],\n",
       "\n",
       "         [[ 0.6499, -0.0156,  0.1526,  ...,  0.0328,  0.2037,  2.0505],\n",
       "          [ 0.6102,  0.0310,  0.0519,  ...,  0.8264,  0.5938,  2.0723],\n",
       "          [ 0.5939,  0.0204, -0.2235,  ...,  0.1480,  0.1647,  1.1388],\n",
       "          [ 0.3704,  0.0456, -0.0781,  ...,  0.4066,  1.0480,  1.5252],\n",
       "          [-0.4944, -0.2282,  0.5823,  ..., -0.3681,  0.9989,  1.6808],\n",
       "          [-0.4859,  0.2872,  1.6986,  ..., -1.0870,  0.4077,  1.1008]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-1.3750e-03,  2.1346e-01,  8.7223e-02,  ..., -7.6918e-02,\n",
       "           -6.7115e-03,  2.2138e-02],\n",
       "          [ 1.5985e-01, -1.1715e-01,  5.5303e-02,  ...,  4.2771e-02,\n",
       "           -9.2193e-02,  2.6507e-01],\n",
       "          [-3.0456e-02, -4.5722e-02,  4.3057e-02,  ...,  3.4132e-01,\n",
       "            1.8246e-01, -6.1055e-02],\n",
       "          [ 5.1535e-02,  1.5516e-02, -1.2907e-01,  ...,  4.8331e-01,\n",
       "           -3.4071e-01,  1.6916e-01],\n",
       "          [ 2.8177e-01, -1.1846e-01, -1.4271e-02,  ..., -7.0597e-02,\n",
       "           -1.6993e-01,  1.2693e-01],\n",
       "          [-1.2850e-02,  1.6945e-01,  8.9031e-02,  ...,  2.7421e-01,\n",
       "           -1.2434e-01, -1.6881e-01]],\n",
       "\n",
       "         [[ 4.1855e-01,  9.4845e-02, -2.8276e-01,  ..., -6.2975e-01,\n",
       "           -2.2798e-01,  1.1444e-01],\n",
       "          [ 4.3063e-01,  1.2558e-01,  2.5983e-02,  ...,  1.4195e-02,\n",
       "            3.5284e-02, -1.6236e-01],\n",
       "          [ 1.8376e-01, -9.5893e-02, -8.9402e-02,  ..., -3.8110e-02,\n",
       "            3.8471e-02, -9.4396e-02],\n",
       "          [ 3.0605e-01,  1.3716e-01,  2.1338e-01,  ...,  3.3054e-01,\n",
       "           -9.2704e-03,  6.0539e-02],\n",
       "          [ 1.4696e-01, -7.0813e-02,  7.8588e-02,  ...,  1.8574e-01,\n",
       "           -9.2263e-03,  2.5192e-02],\n",
       "          [ 3.1357e-01, -1.6313e-01, -6.0731e-02,  ..., -1.2117e-01,\n",
       "            4.5297e-01, -3.2191e-01]],\n",
       "\n",
       "         [[ 1.4803e-01, -7.9859e-02,  1.7464e-01,  ...,  9.3661e-02,\n",
       "            6.1312e-04, -1.6013e-01],\n",
       "          [ 5.4756e-02,  1.5854e-01,  1.7070e-01,  ..., -1.3262e-01,\n",
       "            2.1832e-01,  1.3403e-01],\n",
       "          [ 1.6334e-01, -3.4935e-01,  8.1694e-02,  ...,  4.1916e-02,\n",
       "           -1.6146e-01,  3.8072e-01],\n",
       "          [ 1.3312e-01,  2.2307e-01,  7.5610e-02,  ..., -2.3134e-01,\n",
       "           -2.2669e-01,  1.2615e-01],\n",
       "          [ 2.3559e-02, -1.8010e-01,  9.5744e-02,  ...,  3.2454e-02,\n",
       "            1.6839e-01,  2.4084e-01],\n",
       "          [-2.3653e-01,  1.8250e-01,  8.1221e-02,  ..., -8.5304e-03,\n",
       "           -2.6615e-01,  1.1022e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.2293e-02, -1.0398e-01,  1.8533e-01,  ..., -1.0082e-01,\n",
       "            1.7603e-01, -5.1604e-02],\n",
       "          [-2.0594e-01,  8.1884e-01, -4.1326e-02,  ...,  1.5224e-01,\n",
       "           -1.8116e-01,  1.0859e-01],\n",
       "          [ 1.9113e-02, -1.4841e-01,  1.1824e-01,  ..., -1.7757e-01,\n",
       "            6.2748e-01, -6.5861e-03],\n",
       "          [ 2.4347e-03,  3.4660e-01,  1.0348e-01,  ..., -2.7944e-01,\n",
       "            1.5074e-02, -1.2537e-01],\n",
       "          [ 1.1176e-01, -3.2558e-02,  9.2909e-02,  ...,  1.4524e-01,\n",
       "           -3.8791e-01, -6.8693e-02],\n",
       "          [ 1.5366e-01,  7.4059e-01,  4.0975e-03,  ..., -6.0039e-02,\n",
       "            2.1923e-01,  7.6095e-03]],\n",
       "\n",
       "         [[ 5.2279e-02, -3.0532e-03, -1.4901e-01,  ...,  1.2859e-01,\n",
       "            4.3548e-02, -2.8121e-02],\n",
       "          [-5.0163e-02,  1.2556e-01,  4.0699e-01,  ..., -4.2257e-01,\n",
       "           -2.8600e-01, -2.0617e-01],\n",
       "          [ 5.6820e-03,  1.7188e-02,  7.1619e-02,  ..., -1.5869e-01,\n",
       "           -5.9179e-01,  1.8342e-02],\n",
       "          [-5.5321e-01, -4.5421e-02,  1.2435e-01,  ..., -1.7772e-01,\n",
       "            1.4991e-01, -1.9086e-01],\n",
       "          [-2.7571e-01,  6.1466e-02, -1.2411e-01,  ..., -9.7096e-02,\n",
       "           -2.6790e-01, -2.6752e-02],\n",
       "          [-2.9155e-02, -2.4111e-01,  1.3448e-01,  ..., -1.1362e-01,\n",
       "           -3.1591e-02, -8.6015e-02]],\n",
       "\n",
       "         [[ 4.9555e-02, -4.3616e-01,  1.7431e-01,  ..., -4.0760e-02,\n",
       "           -1.7452e-01, -8.3625e-02],\n",
       "          [ 1.1770e-01,  5.0132e-02, -4.0080e-02,  ...,  1.0307e-01,\n",
       "            4.2189e-01,  2.1956e-02],\n",
       "          [ 3.0901e-01,  2.0623e-01, -2.7016e-01,  ...,  4.6201e-01,\n",
       "            1.0472e-01,  1.2168e-01],\n",
       "          [ 1.3260e-02,  1.5396e-01, -1.1134e-02,  ..., -8.8042e-02,\n",
       "            9.7922e-02,  1.6523e-01],\n",
       "          [ 1.7955e-01, -1.6647e-01, -6.3254e-02,  ...,  2.2546e-02,\n",
       "            4.2080e-01, -5.1586e-02],\n",
       "          [ 3.2680e-01,  2.6795e-01, -2.5206e-02,  ...,  2.7595e-01,\n",
       "            3.8307e-01, -1.8108e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.2960,  1.9136, -1.2463,  ...,  1.2182, -1.2375,  0.9070],\n",
       "          [ 1.1025,  1.9065, -1.2214,  ..., -0.8150, -0.6966, -0.5991],\n",
       "          [ 0.4190,  0.7517,  0.3041,  ..., -0.6906, -1.9605,  0.1089],\n",
       "          [ 0.8115,  1.7348, -0.2620,  ...,  0.0956, -2.0682, -0.6275],\n",
       "          [ 0.1666,  1.2823, -0.0123,  ..., -0.0076, -1.7019,  1.3801],\n",
       "          [ 0.4349,  0.2462, -0.1990,  ..., -0.0384, -1.1916, -0.6510]],\n",
       "\n",
       "         [[-0.9060, -0.5835, -0.4953,  ..., -0.2169,  0.6574, -0.6748],\n",
       "          [-0.3855,  0.3225, -1.7530,  ..., -0.6363, -0.1011, -0.3133],\n",
       "          [-0.3503, -0.3881, -1.8323,  ...,  0.3437, -0.0560, -0.6944],\n",
       "          [-0.1475,  0.0752, -1.9884,  ..., -0.1484, -0.1927, -0.6600],\n",
       "          [-0.6270,  0.1452, -1.5995,  ..., -0.9249,  0.1027, -0.7500],\n",
       "          [-0.5936,  0.7023, -1.1830,  ..., -0.3173, -0.7543, -0.6954]],\n",
       "\n",
       "         [[ 0.6130, -0.0801, -0.1043,  ..., -1.3640,  0.1798, -0.4031],\n",
       "          [ 0.2621,  0.2960, -0.4257,  ..., -0.9321, -0.3072, -0.1838],\n",
       "          [-0.0616,  0.6287,  0.0310,  ..., -0.9805, -0.2324,  0.3998],\n",
       "          [ 0.1206, -0.0045,  0.1816,  ..., -0.9845,  0.1464,  0.1454],\n",
       "          [-0.2974,  0.1328, -0.5478,  ..., -1.2001, -0.0816, -0.1351],\n",
       "          [-0.1553,  0.2537, -0.2816,  ..., -1.2448,  0.1089,  0.0776]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0452, -0.5994, -0.6275,  ..., -0.9381,  0.5664, -0.9555],\n",
       "          [-1.2353,  2.4893,  1.7220,  ..., -0.4591,  0.0334, -0.4500],\n",
       "          [-0.4747, -0.5373,  2.3221,  ..., -1.2056,  0.9213,  0.3081],\n",
       "          [ 0.1013,  0.5810,  2.1050,  ..., -0.2817,  0.2138, -0.2411],\n",
       "          [-2.5457,  2.6518,  2.3163,  ..., -0.7004, -1.7511,  0.2447],\n",
       "          [-0.0101,  1.8119,  2.3046,  ...,  1.6412, -2.0822,  1.5333]],\n",
       "\n",
       "         [[-1.1941, -3.0111,  0.1927,  ...,  1.7736,  1.5745, -1.4711],\n",
       "          [ 0.0058,  0.9014, -0.4577,  ..., -0.7992,  0.5964,  0.1582],\n",
       "          [ 0.1154,  0.5086, -0.5560,  ..., -0.5555,  0.5986,  0.0152],\n",
       "          [ 0.1758,  0.6190, -0.6288,  ..., -0.3588,  0.6330, -0.0194],\n",
       "          [-0.2219,  0.6033, -0.5945,  ..., -0.6583,  0.8900, -0.1169],\n",
       "          [-0.2349,  0.6525, -0.5721,  ..., -0.0572,  0.7026, -0.0046]],\n",
       "\n",
       "         [[ 1.3993,  2.3238,  0.7151,  ..., -0.3898, -0.6635,  0.6006],\n",
       "          [-0.3193,  2.7098,  1.5806,  ...,  1.3237, -1.6097, -1.0944],\n",
       "          [-1.2646,  0.8708,  1.8022,  ...,  1.6715,  0.9642, -0.5812],\n",
       "          [ 1.0691,  2.5857,  1.7466,  ...,  0.5744, -0.0304, -0.1220],\n",
       "          [ 0.0558, -0.2884, -0.2748,  ...,  1.0962,  0.6942, -0.0788],\n",
       "          [-0.4970,  2.5427,  0.6249,  ..., -0.1937, -0.3787,  0.5610]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 6.1680e-01,  4.7459e-02, -1.6400e-01,  ...,  3.6392e-02,\n",
       "           -1.4143e-02,  3.7447e-01],\n",
       "          [-4.6487e-01, -9.5202e-02,  4.8809e-01,  ..., -1.1324e-01,\n",
       "            3.2160e-02, -5.4577e-02],\n",
       "          [ 2.0654e-01,  2.0884e-01, -8.1080e-02,  ..., -1.4220e-01,\n",
       "           -1.1226e-01, -1.0366e-01],\n",
       "          [-4.1191e-02,  1.1688e-01,  3.7401e-01,  ..., -5.2716e-01,\n",
       "            4.7325e-02,  4.4506e-01],\n",
       "          [ 2.5071e-01, -4.7685e-01,  1.8598e-01,  ...,  1.1717e-01,\n",
       "            2.6888e-01, -4.2964e-02],\n",
       "          [ 5.4190e-01, -1.4024e-02, -9.1199e-03,  ..., -6.7507e-01,\n",
       "            2.2725e-01,  1.5204e-01]],\n",
       "\n",
       "         [[ 1.9103e-01, -2.9342e-01, -5.1971e-02,  ..., -6.2753e-02,\n",
       "           -4.3577e-01,  3.3987e-01],\n",
       "          [ 1.2577e-02,  1.6442e-01,  2.1461e-01,  ..., -3.4820e-01,\n",
       "            6.0020e-01,  1.3837e-01],\n",
       "          [ 5.1461e-01,  7.4833e-01,  3.9917e-01,  ..., -3.0741e-01,\n",
       "            1.1237e-01, -1.8318e-01],\n",
       "          [ 2.2020e-01,  4.9876e-01,  1.1067e-01,  ...,  3.5330e-01,\n",
       "            2.4038e-01,  1.6032e-01],\n",
       "          [-4.9889e-01, -7.7906e-01,  9.0797e-02,  ..., -4.5407e-01,\n",
       "            1.3515e-01,  7.2530e-01],\n",
       "          [-3.3516e-01, -7.0654e-02,  2.1798e-01,  ...,  3.1891e-01,\n",
       "            3.4320e-01, -4.7414e-01]],\n",
       "\n",
       "         [[ 5.6172e-02, -1.9886e-01, -5.5177e-02,  ..., -5.6527e-01,\n",
       "            2.0848e-01,  1.4290e-01],\n",
       "          [ 7.4895e-01,  4.4327e-01,  7.3504e-02,  ..., -6.6298e-01,\n",
       "            1.0431e-01,  3.0498e-01],\n",
       "          [ 6.7353e-01,  1.7684e-01,  4.3529e-03,  ..., -7.3224e-01,\n",
       "           -1.0593e-01, -1.9863e-01],\n",
       "          [ 7.2163e-01,  3.8542e-01, -5.4966e-01,  ..., -6.6536e-01,\n",
       "            1.5307e-01, -4.5381e-01],\n",
       "          [ 8.9538e-01,  2.6132e-01,  4.4435e-02,  ..., -4.4985e-01,\n",
       "            2.5574e-01,  4.8045e-01],\n",
       "          [ 7.4611e-01,  2.2631e-01,  2.1273e-01,  ..., -4.7715e-01,\n",
       "            3.2745e-01, -3.4878e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.7437e-01,  6.6419e-01,  5.8862e-03,  ...,  2.6545e-01,\n",
       "           -9.3829e-01, -1.2851e-01],\n",
       "          [-1.0187e-03, -4.6873e-01,  1.6703e-02,  ...,  4.2636e-02,\n",
       "           -3.7575e-01, -4.3186e-01],\n",
       "          [ 8.2060e-02, -5.1500e-03,  1.9795e-01,  ..., -3.9128e-01,\n",
       "           -7.1270e-01, -4.7531e-01],\n",
       "          [-4.0780e-01,  8.9517e-03,  5.5401e-01,  ...,  6.3165e-01,\n",
       "           -3.7216e-01,  1.2635e-01],\n",
       "          [ 1.3056e-01, -9.8567e-01, -3.1100e-01,  ..., -1.1080e-02,\n",
       "           -5.5368e-01, -4.6175e-01],\n",
       "          [-5.7640e-01, -9.2814e-01, -2.1684e-01,  ...,  2.3524e-01,\n",
       "           -5.8535e-01, -2.0015e-01]],\n",
       "\n",
       "         [[ 1.7587e-01, -2.5022e-01, -1.9110e-01,  ...,  2.4227e-01,\n",
       "           -3.6436e+00,  1.3174e-01],\n",
       "          [ 7.7948e-02, -2.2777e-01, -5.0389e-01,  ...,  4.3918e-01,\n",
       "            3.4282e-01, -2.8063e-01],\n",
       "          [-1.1426e-01, -1.3335e-01,  4.0680e-01,  ..., -3.4709e-02,\n",
       "           -1.1054e-01, -9.9933e-03],\n",
       "          [-2.4234e-01,  7.1586e-02, -6.7229e-02,  ..., -1.4217e-01,\n",
       "            1.2507e-01, -1.4565e-02],\n",
       "          [-7.9321e-03, -2.3230e-01,  2.2586e-02,  ...,  3.0156e-01,\n",
       "            8.8251e-02,  8.5392e-02],\n",
       "          [ 7.2933e-02,  4.0113e-01,  1.4728e-01,  ..., -7.3421e-02,\n",
       "           -1.2358e-01, -1.5925e-03]],\n",
       "\n",
       "         [[ 1.4342e-01, -1.7246e-01, -7.9609e-02,  ..., -2.2471e-01,\n",
       "            2.6479e-01, -2.0313e-01],\n",
       "          [-3.8566e-02,  6.0772e-02,  2.6485e-02,  ..., -1.2612e-01,\n",
       "            2.3672e-01,  2.7817e-02],\n",
       "          [ 6.2947e-02, -1.1819e-01,  4.2766e-01,  ...,  3.0907e-01,\n",
       "           -5.1201e-02, -1.8441e-01],\n",
       "          [-2.3602e-01,  7.3060e-02,  2.1379e-01,  ..., -1.5487e-01,\n",
       "            1.0471e-01,  1.5109e-02],\n",
       "          [ 2.9243e-02, -6.1144e-02,  6.1608e-01,  ...,  2.9807e-02,\n",
       "            6.2545e-03,  1.3539e-01],\n",
       "          [ 1.1831e-01, -5.1745e-01,  2.3249e-01,  ..., -8.5965e-02,\n",
       "            1.1813e-04,  3.9351e-02]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.1456, -1.1273,  0.3673,  ..., -0.6838, -0.1361, -0.0517],\n",
       "          [-0.0772, -1.8387, -0.3706,  ..., -0.2931,  0.9700,  0.4367],\n",
       "          [-0.1197, -3.4447, -0.9656,  ..., -1.0802,  0.4537,  0.2757],\n",
       "          [ 0.9273, -4.7986, -0.5415,  ..., -0.3676, -0.1089,  0.0365],\n",
       "          [-1.1042, -1.9889, -0.1840,  ...,  0.2736,  1.6928, -1.2224],\n",
       "          [ 0.4402, -2.8874, -0.2814,  ...,  1.3344,  0.0289,  0.5041]],\n",
       "\n",
       "         [[-0.5067,  0.3084, -0.4240,  ...,  1.1439, -0.5257, -0.4619],\n",
       "          [-1.2821, -0.4558, -1.4620,  ...,  0.1339,  0.2133,  0.5333],\n",
       "          [-0.6923, -0.7141, -1.3123,  ...,  0.3747, -0.7923,  0.9375],\n",
       "          [-1.1131, -0.1809, -1.1377,  ...,  0.1958,  0.0296, -0.0346],\n",
       "          [-1.0484, -0.4673, -0.9257,  ..., -1.1503,  0.3959,  0.2608],\n",
       "          [-1.6353, -1.2183, -2.3563,  ..., -0.6347,  1.4736, -1.1715]],\n",
       "\n",
       "         [[ 1.2456,  3.0580,  3.6921,  ...,  0.6210,  1.6910, -0.7279],\n",
       "          [-3.7747,  2.3132, -1.5452,  ..., -3.7911,  4.2612,  0.9797],\n",
       "          [-2.8551,  1.6494, -2.8952,  ..., -3.1442,  2.0372,  0.4824],\n",
       "          [-3.8225,  0.3225, -3.6876,  ..., -4.1508,  3.2610,  0.8574],\n",
       "          [-3.4380,  0.8505, -2.9431,  ..., -3.9331,  2.5002,  0.4942],\n",
       "          [-3.1088, -1.1516, -3.2471,  ..., -4.3876,  2.0856, -0.3420]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 1.3126, -2.7289, -2.6552,  ...,  0.9230,  0.4588,  2.6957],\n",
       "          [-1.9510,  1.5316,  0.6436,  ..., -1.0590, -1.6601, -0.3654],\n",
       "          [-2.8078,  1.3159,  0.6955,  ..., -0.9807, -1.9328, -0.9251],\n",
       "          [-3.2070,  2.1908,  0.9076,  ...,  0.2124, -3.0516, -1.3679],\n",
       "          [-2.4261,  3.4527,  1.8513,  ..., -0.8819, -2.1837, -0.8438],\n",
       "          [-4.4679,  3.5484,  1.2731,  ...,  0.1083, -2.5323, -0.4035]],\n",
       "\n",
       "         [[ 1.7448,  0.4506,  0.9228,  ...,  0.0168, -0.9884, -0.3162],\n",
       "          [ 2.0277,  1.0380,  0.8378,  ...,  0.4237, -1.5437, -1.8410],\n",
       "          [ 2.5120,  0.7129,  1.4458,  ...,  0.4474, -1.4975, -1.3940],\n",
       "          [ 2.5158,  0.0758,  1.1764,  ...,  0.0484, -1.3252, -1.1680],\n",
       "          [ 1.9494,  0.4096,  1.3296,  ..., -0.2676, -1.0498, -0.6982],\n",
       "          [ 1.8724,  0.2371,  0.6392,  ...,  0.2901, -1.3833, -0.7983]],\n",
       "\n",
       "         [[-0.2627,  0.1570, -0.5609,  ...,  0.2648,  0.2809,  0.1634],\n",
       "          [-0.8984,  1.0906, -0.1785,  ...,  0.5068,  1.1562, -0.2996],\n",
       "          [-1.1169,  0.2763, -0.1208,  ..., -0.2820,  1.2954, -0.2988],\n",
       "          [-0.8190,  0.3819,  0.1604,  ..., -0.0527,  0.4837,  0.0194],\n",
       "          [-0.9340,  0.1225, -0.3348,  ..., -0.0193,  0.9961, -0.1635],\n",
       "          [-0.6914,  0.1389, -0.4067,  ..., -0.1481,  0.4993,  0.9379]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 4.3544e-03, -2.5976e-02, -1.5382e-01,  ...,  7.4692e-03,\n",
       "            8.9665e-03, -5.4475e-01],\n",
       "          [ 5.0316e-01, -8.2779e-01,  5.7694e-01,  ...,  6.0928e-01,\n",
       "           -2.5445e-01,  7.5457e-01],\n",
       "          [-3.0093e-01, -4.7443e-01,  2.6359e-01,  ..., -1.1357e-01,\n",
       "            4.3913e-01,  9.3580e-01],\n",
       "          [-5.3768e-01, -1.1547e+00,  3.0175e-01,  ...,  9.6758e-02,\n",
       "            2.5840e-01,  3.1752e-01],\n",
       "          [ 6.0892e-01, -6.1936e-01,  3.4307e-01,  ...,  1.8073e-01,\n",
       "           -2.2628e-01,  4.4342e-01],\n",
       "          [ 5.9306e-02,  6.1586e-01, -1.2642e+00,  ...,  2.2944e-01,\n",
       "           -6.8444e-02, -4.4262e-01]],\n",
       "\n",
       "         [[ 4.7577e-02, -1.8416e-02,  1.0956e-02,  ...,  1.2604e-02,\n",
       "           -8.7699e-03,  3.7373e-02],\n",
       "          [-3.1546e-01,  1.2666e-01, -9.2867e-01,  ...,  2.2893e-01,\n",
       "            6.6696e-02, -9.6725e-02],\n",
       "          [ 3.3981e-01,  2.4964e-01, -1.9469e-01,  ...,  4.6156e-01,\n",
       "            7.5050e-01, -1.7058e-01],\n",
       "          [ 1.6484e+00,  8.5711e-02,  5.5345e-01,  ..., -5.5190e-02,\n",
       "            6.4247e-01,  3.6776e-01],\n",
       "          [ 4.6872e-01,  1.3577e-01,  2.1705e-01,  ...,  8.4017e-02,\n",
       "            9.2435e-01, -5.1169e-02],\n",
       "          [ 3.6851e-03,  3.8689e-01, -5.3654e-01,  ...,  6.5088e-03,\n",
       "            4.5372e-01, -1.7107e+00]],\n",
       "\n",
       "         [[ 3.7145e-02, -7.8628e-01, -4.6597e-02,  ...,  4.6333e-02,\n",
       "           -8.0347e-04, -6.7108e-02],\n",
       "          [ 5.7614e-02, -5.0429e-01,  9.8423e-02,  ..., -4.7305e-01,\n",
       "           -3.1029e-01, -9.9538e-02],\n",
       "          [-1.3832e-01, -1.9034e+00, -1.6011e-01,  ..., -2.8696e-01,\n",
       "            3.0619e-01,  7.0110e-01],\n",
       "          [ 1.0139e-01, -1.6282e+00,  2.3864e-01,  ..., -1.5583e-01,\n",
       "            1.6083e-01, -2.3057e-01],\n",
       "          [ 4.1509e-01, -1.4933e+00,  1.4051e-01,  ...,  4.6117e-01,\n",
       "            1.9808e-01,  2.3704e-01],\n",
       "          [ 3.5898e-01, -1.3297e+00,  4.1358e-01,  ..., -4.0991e-01,\n",
       "           -1.2689e-01,  2.8209e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 9.7488e-03, -8.5395e-02,  1.3394e+00,  ..., -5.0610e-02,\n",
       "            1.7945e-01,  2.1192e-03],\n",
       "          [ 1.9679e-03, -3.7652e-01,  2.0588e+00,  ...,  4.5677e-03,\n",
       "            1.1975e-01, -1.9288e-01],\n",
       "          [-5.1057e-02, -2.8130e-01,  1.7353e+00,  ..., -1.2547e-02,\n",
       "            3.3168e-01,  1.7186e-01],\n",
       "          [ 1.2990e-01, -6.2126e-01,  1.8255e+00,  ..., -3.6585e-01,\n",
       "           -2.5030e-01, -2.9716e-01],\n",
       "          [-1.6523e-01, -2.0110e-01,  1.4259e+00,  ...,  5.6909e-01,\n",
       "            1.4932e-01,  3.9897e-01],\n",
       "          [ 4.4455e-02, -6.5247e-01,  2.0971e+00,  ...,  1.0017e-01,\n",
       "           -1.8739e-02,  4.5427e-01]],\n",
       "\n",
       "         [[ 1.7218e-02, -1.0799e-01, -1.4576e-01,  ...,  1.3877e-01,\n",
       "            1.2149e-01,  1.7165e-01],\n",
       "          [-1.0924e-01, -3.1596e-02, -3.2168e-01,  ...,  5.1102e-01,\n",
       "           -9.8338e-02, -1.4682e+00],\n",
       "          [ 9.5748e-01, -2.6778e-01, -8.4286e-01,  ...,  6.8687e-01,\n",
       "           -6.6687e-01, -1.8852e-01],\n",
       "          [ 4.8021e-01, -7.7334e-01, -2.6955e-01,  ...,  7.3668e-02,\n",
       "           -3.2097e-01, -5.1338e-01],\n",
       "          [-1.5631e-01,  1.7502e-01,  9.3253e-02,  ...,  1.9042e-01,\n",
       "            5.9162e-02, -2.9092e-01],\n",
       "          [ 1.0862e+00, -1.3334e-01,  7.8079e-03,  ..., -4.6349e-01,\n",
       "           -6.8721e-01,  3.8216e-01]],\n",
       "\n",
       "         [[ 1.5924e-02,  2.4134e-02,  4.0739e-02,  ..., -2.0048e-02,\n",
       "            2.3951e-01,  2.5629e-02],\n",
       "          [-1.3449e-01, -4.1940e-01,  5.8211e-01,  ..., -3.7284e-01,\n",
       "           -1.9872e+00,  7.7173e-01],\n",
       "          [-6.1435e-02,  4.3734e-02,  3.4132e-02,  ..., -6.0017e-02,\n",
       "           -2.3490e+00,  1.6689e-01],\n",
       "          [ 1.2385e-01, -5.4594e-01, -2.1459e-01,  ..., -4.6963e-01,\n",
       "           -1.9060e+00,  1.1504e-01],\n",
       "          [ 1.6463e-01, -2.5400e-02, -6.2596e-01,  ..., -3.9431e-02,\n",
       "           -1.6120e+00,  2.6590e-01],\n",
       "          [ 1.3701e-01,  1.2728e-01, -2.4663e-01,  ...,  1.8903e-01,\n",
       "           -1.2014e+00, -5.6319e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 0.0350, -0.2264,  0.1487,  ..., -0.8644,  0.7422, -1.1889],\n",
       "          [-2.4785, -0.5544, -0.5822,  ...,  1.0721,  0.0401,  0.8531],\n",
       "          [ 0.7729, -0.3914, -0.4243,  ...,  0.1407,  0.5210,  1.6679],\n",
       "          [ 0.4912, -2.0634, -0.2771,  ...,  0.1930, -0.5374,  1.4087],\n",
       "          [-1.4439, -1.3704, -1.2532,  ...,  0.0146,  0.0891, -0.6912],\n",
       "          [ 0.1307, -2.3767,  0.2170,  ...,  2.1170,  0.8991, -0.2204]],\n",
       "\n",
       "         [[ 0.7939,  0.2118,  0.0294,  ..., -0.1649, -1.1021, -0.1849],\n",
       "          [ 1.0900, -1.7915,  0.4854,  ...,  1.6086,  4.1652,  0.7871],\n",
       "          [ 0.8751, -1.0497, -0.3589,  ..., -0.0231,  5.8170,  0.3407],\n",
       "          [ 0.2449, -1.2162, -0.4761,  ..., -0.0567,  5.0813,  1.7289],\n",
       "          [ 0.1333, -2.1742, -0.1745,  ...,  0.3841,  4.4884,  1.3414],\n",
       "          [-1.8039, -0.9515, -0.4917,  ..., -0.2000,  3.8676,  1.6433]],\n",
       "\n",
       "         [[ 0.3562, -0.3584, -0.3298,  ...,  0.3392,  1.4522,  0.2502],\n",
       "          [-0.0775, -6.0657, -2.1099,  ..., -1.9630, -1.6544, -6.0567],\n",
       "          [-0.8258, -7.1295, -2.0128,  ..., -3.9775, -2.9511, -6.4458],\n",
       "          [-1.7001, -5.9406, -0.6444,  ..., -4.7947, -2.9556, -5.2640],\n",
       "          [-0.8519, -6.2243, -3.0569,  ..., -2.3183, -2.2748, -5.9659],\n",
       "          [-2.2849, -6.0773, -2.9035,  ..., -3.3528, -2.5066, -5.4061]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2304,  1.7488,  0.5235,  ...,  0.2590,  0.4497, -1.6957],\n",
       "          [ 0.2040, -6.3660,  2.0966,  ..., -2.8107, -1.3736,  4.0563],\n",
       "          [ 0.7544, -5.7104,  1.2180,  ..., -2.3158, -1.7475,  7.2632],\n",
       "          [ 0.5730, -5.4708,  0.5165,  ..., -2.7895, -2.3742,  6.9896],\n",
       "          [ 1.3673, -5.8358,  1.7809,  ..., -2.4173, -2.4470,  5.2355],\n",
       "          [ 4.8317, -7.7679,  2.4041,  ..., -1.5532, -1.2112,  4.6195]],\n",
       "\n",
       "         [[ 0.0490, -0.0349,  0.1538,  ..., -0.0848, -0.1092, -0.1452],\n",
       "          [ 0.7487, -1.3799,  0.2213,  ..., -1.6105,  0.9107, -0.4709],\n",
       "          [ 1.1487, -1.0692, -0.0596,  ..., -1.6891, -0.5701,  0.0764],\n",
       "          [ 0.7159, -0.2850, -0.7636,  ..., -1.3575, -1.3347, -0.5763],\n",
       "          [-0.6770, -0.4376, -0.9956,  ..., -0.5869,  0.8858, -0.7256],\n",
       "          [-0.0325,  0.5544, -0.5464,  ..., -1.8886, -0.7169,  0.5976]],\n",
       "\n",
       "         [[ 0.4026, -0.0697,  1.9083,  ..., -0.2491, -0.2030, -0.9976],\n",
       "          [ 3.4726,  1.9864, -2.5669,  ...,  1.4320, -0.1796,  2.9878],\n",
       "          [ 2.5647,  0.6817, -1.3994,  ...,  2.6535, -1.3135,  5.2703],\n",
       "          [ 1.6921,  2.2323, -1.8314,  ...,  0.3825,  0.1784,  4.4097],\n",
       "          [ 2.8230,  1.9331, -1.6152,  ...,  1.1858,  0.5571,  5.4834],\n",
       "          [ 3.1967,  1.4888, -2.5572,  ...,  0.4277,  1.7126,  4.0815]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 3.9053e-02,  6.2440e-02, -1.0137e-02,  ...,  1.5568e-02,\n",
       "            9.6634e-02,  3.9822e-02],\n",
       "          [-2.9125e-01, -1.3314e+00, -6.2614e-01,  ...,  1.1748e-01,\n",
       "           -1.2357e+00, -5.2370e-01],\n",
       "          [ 6.7084e-01, -1.0475e+00,  1.1339e-01,  ...,  4.7398e-02,\n",
       "           -7.9936e-01, -1.2462e+00],\n",
       "          [-5.8959e-02, -5.6570e-01,  8.0724e-01,  ...,  3.4245e-01,\n",
       "           -1.2297e+00,  1.2285e-01],\n",
       "          [ 3.7675e-01, -6.5339e-01, -4.7815e-01,  ..., -4.2513e-01,\n",
       "           -1.2179e+00, -1.2674e+00],\n",
       "          [ 7.5889e-01, -4.9165e-01, -2.1167e-02,  ...,  3.5531e-02,\n",
       "           -1.2892e+00, -3.7268e-02]],\n",
       "\n",
       "         [[-4.1332e-02,  7.0995e-04,  7.4176e-02,  ..., -4.2951e-02,\n",
       "           -3.3709e-02, -4.3846e-02],\n",
       "          [ 3.1813e-01, -2.2890e-01, -3.7030e-01,  ...,  3.6922e-01,\n",
       "            3.2075e-01,  3.0409e-01],\n",
       "          [-2.9079e-01, -3.8842e-01,  2.2212e-01,  ...,  5.2425e-01,\n",
       "            3.2069e-01, -6.2795e-01],\n",
       "          [-5.1425e-02, -5.4000e-01, -4.6267e-01,  ...,  2.3313e-01,\n",
       "            3.2309e-01, -7.7413e-01],\n",
       "          [ 2.8734e-01,  2.4609e-01,  5.0713e-02,  ...,  3.8068e-01,\n",
       "            9.0266e-01,  6.4990e-01],\n",
       "          [-2.1102e-01,  5.6136e-01,  1.3281e-01,  ...,  5.2254e-01,\n",
       "            5.9754e-01, -2.7479e-01]],\n",
       "\n",
       "         [[ 3.0006e-02, -1.0155e-01, -6.4820e-02,  ..., -2.4092e-02,\n",
       "            8.3062e-02, -1.5113e-01],\n",
       "          [-5.4489e-02,  1.2020e-02, -3.1985e-01,  ...,  1.7228e-01,\n",
       "           -1.7819e-01,  2.2971e-01],\n",
       "          [-2.2635e-01,  3.4949e-01, -1.4329e-02,  ..., -1.0870e-01,\n",
       "           -2.9302e-01,  1.5427e-01],\n",
       "          [ 3.3766e-01,  3.2166e-02,  4.3514e-01,  ..., -4.3706e-01,\n",
       "           -2.5563e-01,  1.6631e-01],\n",
       "          [-4.0353e-01, -6.2375e-01, -3.0634e-01,  ...,  9.2576e-02,\n",
       "           -1.7890e-02,  2.4411e-01],\n",
       "          [ 3.1413e-01,  6.4414e-01, -4.5524e-01,  ..., -2.0878e-01,\n",
       "           -6.3362e-02,  7.7726e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.6603e-02,  1.2395e-01, -3.2500e-03,  ..., -2.1699e-02,\n",
       "            6.7866e-02, -4.0074e-02],\n",
       "          [ 2.4782e-01, -1.1412e+00,  9.0066e-01,  ...,  8.4813e-01,\n",
       "           -3.4056e-01,  3.2995e-01],\n",
       "          [ 7.3253e-02, -3.3507e-01,  4.9605e-02,  ...,  4.6377e-01,\n",
       "            4.6488e-01,  6.7319e-01],\n",
       "          [ 1.2246e-01, -3.2355e-01, -5.2998e-01,  ...,  1.8157e-01,\n",
       "           -4.9123e-01, -4.5898e-02],\n",
       "          [ 5.2231e-01,  5.1562e-02, -7.4726e-01,  ...,  7.0675e-01,\n",
       "            6.9615e-01, -4.4289e-01],\n",
       "          [ 7.1950e-01,  1.0863e-02,  9.4711e-01,  ...,  1.1055e+00,\n",
       "           -5.7585e-01, -1.0397e+00]],\n",
       "\n",
       "         [[-1.6513e-01, -1.2483e-01, -7.3289e-02,  ..., -2.3024e-01,\n",
       "           -2.4535e-02, -4.1402e-02],\n",
       "          [ 1.9336e-01,  1.2655e+00, -2.1122e-01,  ...,  9.2317e-01,\n",
       "            9.1207e-02,  8.7448e-01],\n",
       "          [ 6.6979e-01, -6.4617e-02, -4.1746e-01,  ..., -2.8997e-01,\n",
       "            4.6338e-01,  6.6256e-01],\n",
       "          [ 1.0853e+00, -3.9985e-01, -8.2000e-01,  ..., -1.2025e+00,\n",
       "            6.9599e-01, -8.5595e-02],\n",
       "          [-4.2684e-01, -2.5579e-01,  1.2848e-01,  ...,  7.6499e-01,\n",
       "            6.1694e-01, -2.7077e-01],\n",
       "          [ 2.8796e-01,  4.3871e-01,  4.4223e-01,  ...,  5.5806e-01,\n",
       "           -3.7968e-01,  7.4981e-01]],\n",
       "\n",
       "         [[ 1.2475e-01, -6.5489e-02, -2.0528e-02,  ..., -2.3071e-02,\n",
       "           -9.9067e-02, -1.0746e-01],\n",
       "          [-2.7051e-02,  9.2897e-01,  1.2189e-01,  ...,  2.8790e-02,\n",
       "           -8.6577e-01, -3.5226e-01],\n",
       "          [-5.5012e-01,  9.4293e-02,  7.0442e-01,  ..., -1.0172e-01,\n",
       "           -3.5475e-01, -7.4012e-01],\n",
       "          [ 7.8987e-02,  4.3233e-01,  3.0187e-01,  ..., -1.0486e-01,\n",
       "            3.1759e-01, -5.6530e-01],\n",
       "          [-3.3725e-01,  8.8322e-01, -1.4388e-01,  ...,  7.4928e-02,\n",
       "           -3.7408e-01,  4.9078e-01],\n",
       "          [ 7.6808e-01, -2.7450e-01,  2.0048e-01,  ...,  1.6888e-01,\n",
       "            1.0281e-01,  2.2930e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.8759, -0.1423,  0.3366,  ..., -0.9544,  0.0397, -2.9554],\n",
       "          [ 0.2013,  0.8357, -2.3871,  ...,  0.6184, -2.0518,  7.0358],\n",
       "          [ 1.6323,  0.6723, -3.3886,  ..., -2.1525, -2.3463,  8.2134],\n",
       "          [ 2.8803,  1.1933, -3.2683,  ..., -2.0110, -2.3991,  8.7216],\n",
       "          [ 2.5098, -1.2507, -3.0207,  ..., -0.8951, -2.1705,  6.9959],\n",
       "          [ 0.6988, -1.8147, -3.1691,  ..., -1.4260, -1.0751,  7.6493]],\n",
       "\n",
       "         [[ 0.3793, -0.0816,  0.4614,  ..., -0.1451, -0.0673, -2.2388],\n",
       "          [-2.0327, -0.2174,  2.2854,  ..., -1.5398, -0.3219,  5.5216],\n",
       "          [-0.0365,  0.4379,  2.3723,  ..., -1.3488, -1.3059,  6.8028],\n",
       "          [-0.7059,  1.0853,  2.4524,  ..., -1.3564,  0.2407,  6.3841],\n",
       "          [-3.9098,  0.9892,  2.8853,  ..., -0.5788, -1.0413,  5.8318],\n",
       "          [-0.1596, -0.4298,  4.1600,  ...,  0.3090,  0.4484,  6.0259]],\n",
       "\n",
       "         [[ 0.1307, -0.6545, -0.2205,  ...,  0.1478,  0.2596, -0.1673],\n",
       "          [-0.8717,  1.7662,  0.6282,  ...,  0.7070,  0.3346,  0.2189],\n",
       "          [-0.1991,  2.1491, -1.0732,  ...,  0.3747,  0.5454,  0.8377],\n",
       "          [ 1.1513,  2.5494, -0.2377,  ...,  1.0739,  0.8210, -1.8229],\n",
       "          [-0.2677,  1.4290,  0.0946,  ..., -0.0895,  0.1001, -1.0034],\n",
       "          [-0.1324,  3.7848,  1.4446,  ..., -1.3661,  1.9439,  0.6529]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3820,  0.0203, -0.0206,  ...,  1.2553,  0.0580,  1.7912],\n",
       "          [ 1.0540,  1.1860, -0.8557,  ..., -3.0677, -0.5317, -1.4993],\n",
       "          [-0.0249, -0.4392,  0.6158,  ..., -3.1866, -1.6445, -0.2627],\n",
       "          [ 0.5153, -0.5820,  0.7970,  ..., -2.3834, -0.1225, -0.0616],\n",
       "          [ 0.9729,  1.9352, -0.4093,  ..., -2.0133,  0.0252, -0.0304],\n",
       "          [-0.2208, -0.8410, -0.8238,  ..., -2.6493, -0.8013,  0.2762]],\n",
       "\n",
       "         [[-0.3239, -0.1437,  0.2314,  ...,  0.2498, -0.0350,  0.0108],\n",
       "          [ 1.1015, -1.7410,  0.8132,  ...,  0.9068,  0.7845, -0.0804],\n",
       "          [-0.5133, -0.2691,  0.2340,  ...,  0.2386, -0.2484,  0.2977],\n",
       "          [-0.5248, -0.3270,  0.5648,  ...,  0.6206,  0.6610, -1.0241],\n",
       "          [ 0.6660, -1.1222, -0.5018,  ...,  0.8417, -0.3755, -0.5048],\n",
       "          [-0.2540,  0.4051,  1.4026,  ..., -0.4808, -0.0293,  1.5710]],\n",
       "\n",
       "         [[ 3.4291,  2.1852, -2.1160,  ..., -2.8447, -3.8809, -1.2223],\n",
       "          [-3.5767,  3.0068,  1.0752,  ..., -1.7434,  7.2132, -1.7089],\n",
       "          [-2.9028,  0.6405,  6.0079,  ..., -0.9813,  9.3741, -3.7637],\n",
       "          [-1.1428, -2.3664,  7.7938,  ..., -2.3620,  8.7161, -5.0213],\n",
       "          [-6.0681, -2.6422,  4.1371,  ...,  0.2272,  6.2067, -2.7887],\n",
       "          [-6.6134, -4.1842,  5.0347,  ...,  3.9877,  9.7508, -4.8463]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-0.0051, -0.0479,  0.0275,  ...,  0.0623,  0.0272,  0.0653],\n",
       "          [ 0.4739,  0.3182, -0.4821,  ..., -0.3299, -0.7168, -0.8381],\n",
       "          [-0.3500,  0.6393,  0.0029,  ..., -0.1702,  0.2369, -0.0238],\n",
       "          [-0.2939, -0.0140,  0.2569,  ..., -0.3382,  0.7803,  0.4743],\n",
       "          [-0.4177, -0.2968, -0.8806,  ...,  0.3301, -0.6060, -0.3520],\n",
       "          [-0.4694,  1.3709, -0.4404,  ...,  0.3972,  0.1146, -0.3472]],\n",
       "\n",
       "         [[-0.0644, -0.0277, -0.1326,  ..., -0.0430,  0.0473, -0.0184],\n",
       "          [ 0.0332,  0.0705,  0.0737,  ...,  0.0296, -0.5605, -0.1185],\n",
       "          [ 0.2478,  0.8233,  0.1199,  ...,  0.7001,  0.3807,  0.1071],\n",
       "          [-0.1637,  0.6469,  0.0500,  ...,  0.9330,  0.2621,  0.0207],\n",
       "          [ 0.6106,  0.5237,  0.3747,  ...,  0.3048,  0.5023, -0.0459],\n",
       "          [-0.8367,  0.0895, -0.0593,  ..., -0.7794, -0.4409,  0.2695]],\n",
       "\n",
       "         [[ 0.0612,  0.0940,  0.0983,  ...,  0.0095, -0.0748, -0.0067],\n",
       "          [-0.6254,  0.6234, -0.3934,  ..., -0.7809, -0.7821,  0.3429],\n",
       "          [ 0.2983,  0.5247,  0.9045,  ...,  0.7688,  0.7207,  0.4450],\n",
       "          [-0.4342,  0.8860, -0.8577,  ...,  0.8392,  1.5543,  0.3632],\n",
       "          [-0.4258,  0.0289,  0.7071,  ...,  0.2865, -0.5503, -0.0125],\n",
       "          [ 0.8690, -0.3583, -0.8721,  ...,  0.0254,  0.7909,  0.6791]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0029,  0.0826, -0.0769,  ...,  0.0481,  0.0349, -0.1364],\n",
       "          [ 0.3192,  0.1950,  1.4622,  ..., -0.4541,  0.8610, -0.2516],\n",
       "          [ 0.0896,  0.0899, -0.0895,  ..., -0.6565, -0.2586,  0.1180],\n",
       "          [-0.3253,  0.1156, -0.1514,  ..., -0.3422, -0.8541,  0.7489],\n",
       "          [-0.0303, -0.3024,  0.8820,  ...,  0.2300,  0.4932, -0.5682],\n",
       "          [ 0.1247, -0.2935, -0.3364,  ...,  0.5597, -0.5948, -0.9490]],\n",
       "\n",
       "         [[-0.1291, -0.0459,  0.1048,  ..., -0.0668,  0.0575, -0.0277],\n",
       "          [ 0.4585,  0.5887,  0.6263,  ..., -0.5915, -1.0358, -0.2343],\n",
       "          [ 0.6413, -0.5534, -1.0556,  ...,  1.6556, -0.4629, -0.0300],\n",
       "          [-0.5785, -0.4196, -0.8359,  ...,  2.5761, -0.3277, -1.3201],\n",
       "          [ 0.2319, -0.9643, -2.8148,  ..., -1.5018, -1.0209,  1.4197],\n",
       "          [ 0.0496,  0.5156, -0.6752,  ..., -0.8031, -0.5163, -0.1779]],\n",
       "\n",
       "         [[-0.0227, -0.0112, -0.0210,  ..., -0.0262,  0.0076, -0.0163],\n",
       "          [-0.6655, -0.4495,  0.3046,  ...,  0.0728, -0.7890,  0.4110],\n",
       "          [ 0.2487, -0.0173, -0.1157,  ...,  0.2402, -0.0165, -0.6080],\n",
       "          [ 0.0043, -0.0321, -0.4576,  ...,  0.0468, -0.1307, -0.2420],\n",
       "          [-0.4709, -0.3819,  0.0927,  ...,  0.1699,  0.4158,  0.5451],\n",
       "          [ 0.5487, -0.0061,  0.8331,  ...,  0.0565,  0.5322,  0.1758]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[ 2.4347e-02, -2.9254e-01,  2.3215e-01,  ...,  1.7019e+00,\n",
       "           -2.1743e-01, -6.8189e-02],\n",
       "          [-4.9371e-01,  2.0643e+00,  1.5274e+00,  ..., -3.1800e+00,\n",
       "           -4.4670e-01, -4.6808e-01],\n",
       "          [-8.8529e-01,  1.0824e+00,  7.7104e-01,  ..., -1.6128e+00,\n",
       "            1.6048e+00, -1.9285e+00],\n",
       "          [-1.0662e+00,  1.5710e-01, -1.2813e+00,  ..., -3.6148e+00,\n",
       "            2.6932e-01, -7.6606e-01],\n",
       "          [-7.6712e-01,  1.2157e+00, -3.3358e-01,  ..., -3.9602e+00,\n",
       "           -1.0522e+00, -1.1936e+00],\n",
       "          [ 6.9954e-01, -4.6156e-01, -1.2396e+00,  ..., -3.4736e+00,\n",
       "           -6.6779e-01, -1.0402e+00]],\n",
       "\n",
       "         [[ 1.7591e-01,  9.9015e-01, -1.4204e+00,  ..., -1.3284e-01,\n",
       "            2.6606e-01,  9.3262e-01],\n",
       "          [-3.7605e-01, -4.7284e+00, -4.1708e-01,  ..., -1.3905e+00,\n",
       "            4.5550e-01, -2.3597e+00],\n",
       "          [ 1.4357e+00, -3.8432e+00, -8.5538e-01,  ..., -3.8684e-01,\n",
       "           -4.2501e-01, -3.2324e-01],\n",
       "          [ 1.0817e+00, -3.2295e+00,  1.7198e+00,  ...,  2.5055e+00,\n",
       "            2.9194e-01, -5.8226e-01],\n",
       "          [-6.7146e-01, -3.8338e+00,  2.7938e+00,  ...,  8.7796e-02,\n",
       "           -1.1044e+00, -5.9817e-01],\n",
       "          [ 7.5841e-01, -3.3355e+00,  3.2832e+00,  ...,  3.5043e-01,\n",
       "           -2.0627e+00, -1.0487e+00]],\n",
       "\n",
       "         [[-6.8551e-01,  2.4585e-01, -4.7651e-02,  ...,  1.9179e-01,\n",
       "            3.1029e-02, -2.8196e-01],\n",
       "          [ 1.5396e+00, -1.1204e+00,  3.8720e-01,  ..., -3.8409e-01,\n",
       "           -6.0445e-01, -6.1589e-01],\n",
       "          [ 1.9069e+00, -1.8277e+00,  1.0096e-02,  ..., -3.5727e-01,\n",
       "            4.4298e-01, -7.3319e-01],\n",
       "          [ 6.8653e-01, -1.7684e+00, -4.2119e-01,  ..., -5.4319e-01,\n",
       "           -5.8049e-02,  4.1320e-01],\n",
       "          [-9.7592e-01,  5.2031e-01, -1.2705e+00,  ..., -2.5806e+00,\n",
       "           -6.2577e-01, -7.2070e-01],\n",
       "          [ 1.1173e+00, -1.0242e+00,  1.5502e-01,  ..., -8.9230e-01,\n",
       "           -9.9271e-01,  2.0670e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.7420e-02,  1.1828e-01,  1.4192e-01,  ..., -1.0730e-01,\n",
       "            2.5166e-02,  1.5478e-01],\n",
       "          [ 2.8947e-01,  6.3888e-01, -9.6204e-01,  ...,  9.2778e-01,\n",
       "           -1.4605e+00,  5.0861e-01],\n",
       "          [ 9.1016e-01, -3.4710e-01, -1.9885e-01,  ...,  1.2893e-01,\n",
       "           -1.9651e+00, -6.6621e-01],\n",
       "          [ 1.4294e+00, -7.2882e-01,  6.0828e-02,  ...,  2.9913e-01,\n",
       "           -3.5964e-01,  4.2147e-01],\n",
       "          [ 2.1877e+00, -1.2768e-01, -5.5036e-01,  ..., -7.7978e-01,\n",
       "           -9.8778e-01,  2.8046e-01],\n",
       "          [ 1.3432e+00, -1.2449e+00,  5.6190e-01,  ...,  9.9586e-02,\n",
       "           -6.9170e-01, -7.9335e-01]],\n",
       "\n",
       "         [[-3.0103e+00,  4.1023e-01, -2.6863e-03,  ..., -4.6983e-01,\n",
       "           -3.4831e-01,  1.2351e+00],\n",
       "          [ 4.4673e+00,  7.0358e-01,  5.3695e-01,  ..., -6.9620e-01,\n",
       "            3.4047e-01, -6.6281e-01],\n",
       "          [ 4.8521e+00,  1.5337e+00,  2.2589e+00,  ..., -8.3289e-01,\n",
       "           -8.2340e-01,  1.1247e+00],\n",
       "          [ 4.7403e+00, -3.5186e-02, -2.3707e+00,  ..., -3.8436e+00,\n",
       "           -2.9416e-01, -5.1185e-02],\n",
       "          [ 4.0611e+00,  6.3900e-02, -3.1622e-01,  ..., -1.4991e+00,\n",
       "           -4.8562e-01, -1.6275e-01],\n",
       "          [ 5.4709e+00,  1.2636e+00, -6.1210e-01,  ..., -1.5332e+00,\n",
       "           -3.7585e-01, -8.1165e-01]],\n",
       "\n",
       "         [[-1.7083e-02, -2.3070e-01,  7.7615e-03,  ..., -1.7216e-01,\n",
       "            3.4017e-01,  8.6432e-02],\n",
       "          [ 1.1478e+00, -1.6127e+00,  3.7752e-01,  ..., -1.5658e+00,\n",
       "            9.6809e-01, -1.2763e+00],\n",
       "          [ 5.5477e-01, -6.3461e-01, -1.2568e+00,  ..., -1.4298e+00,\n",
       "            7.5008e-01, -1.1412e+00],\n",
       "          [-1.2134e+00, -2.0188e+00,  2.3437e-01,  ...,  8.8593e-01,\n",
       "           -1.0141e-01,  2.2406e-01],\n",
       "          [ 7.4939e-01, -2.2432e-01, -2.4828e+00,  ...,  1.9351e-01,\n",
       "            8.8794e-01, -6.9253e-02],\n",
       "          [ 1.3642e+00, -2.3246e-01, -5.3350e-01,  ...,  3.2172e-01,\n",
       "            2.7140e-02, -5.8689e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[-2.3872e-02, -2.7107e-02,  4.6739e-03,  ..., -6.5991e-03,\n",
       "           -3.1929e-02,  3.5228e-01],\n",
       "          [ 2.4861e+00,  2.6262e-01,  4.6936e-02,  ..., -2.1140e-01,\n",
       "           -1.5599e-01, -9.4099e-01],\n",
       "          [ 7.4382e-01,  1.1989e-01,  3.0245e-01,  ..., -9.7031e-01,\n",
       "            1.5625e+00, -1.6587e+00],\n",
       "          [ 1.1954e+00, -3.5423e-01,  4.2937e-01,  ..., -6.6578e-01,\n",
       "            1.2618e-01, -5.9358e-01],\n",
       "          [-1.3654e-01, -1.7986e-02, -2.1802e-01,  ..., -1.2367e-01,\n",
       "           -9.0308e-02, -1.0414e+00],\n",
       "          [-2.1994e-01,  1.5051e+00,  1.8286e-02,  ...,  6.5822e-01,\n",
       "            7.5817e-01, -1.1408e+00]],\n",
       "\n",
       "         [[ 2.8633e-04, -1.8985e-02,  8.9738e-03,  ..., -1.9715e-02,\n",
       "            2.3859e-02, -1.6117e-03],\n",
       "          [ 4.7184e-01,  2.7967e-01,  1.6244e-01,  ...,  3.1922e-01,\n",
       "            1.4079e+00, -8.4385e-01],\n",
       "          [ 1.0632e+00,  1.9404e-02,  7.4933e-01,  ..., -1.7844e+00,\n",
       "            5.6811e-01, -6.0121e-01],\n",
       "          [ 5.5077e-01,  7.7017e-02, -3.0968e-02,  ...,  6.8239e-01,\n",
       "            1.1591e+00, -1.7971e-01],\n",
       "          [ 3.1122e-01, -2.0168e+00,  7.4934e-01,  ..., -4.2611e-01,\n",
       "            1.4391e+00, -1.5516e+00],\n",
       "          [-1.1678e+00,  5.5546e-01,  4.7743e-01,  ..., -7.0970e-01,\n",
       "            9.0825e-01, -2.8070e-01]],\n",
       "\n",
       "         [[-5.2501e-02,  1.6404e-03, -3.9048e-02,  ..., -3.6421e-02,\n",
       "            3.7877e-03, -7.9780e-02],\n",
       "          [-9.8803e-01, -1.4744e+00,  5.0408e-02,  ..., -1.3350e-01,\n",
       "           -4.6720e-01,  5.1679e-01],\n",
       "          [-1.1619e+00, -1.1711e+00,  1.6499e-01,  ...,  9.2410e-01,\n",
       "            1.3579e-01,  5.2706e-01],\n",
       "          [-1.1270e+00, -3.7720e-01,  5.0133e-01,  ...,  4.0183e-01,\n",
       "           -4.4983e-01, -8.0523e-01],\n",
       "          [-1.3302e+00, -5.1226e-01,  5.2836e-01,  ...,  8.5761e-01,\n",
       "           -8.5231e-01, -4.5358e-01],\n",
       "          [-3.7171e-02,  6.2644e-01,  9.4517e-01,  ...,  1.0198e+00,\n",
       "           -1.7341e-01,  3.4055e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-3.2781e-01, -1.9825e-01, -6.0809e-02,  ..., -4.8387e-01,\n",
       "            2.1853e-01,  1.0622e-01],\n",
       "          [ 3.5642e-01, -2.0877e+00, -1.1691e+00,  ...,  3.3633e+00,\n",
       "            7.2876e-01, -5.5404e-02],\n",
       "          [ 4.5821e-01, -2.2897e+00,  2.2296e-01,  ...,  1.8212e+00,\n",
       "           -1.1473e-01, -1.4756e-01],\n",
       "          [ 1.2325e+00, -1.1541e+00,  1.4849e+00,  ...,  1.8695e+00,\n",
       "           -7.4459e-01, -1.7549e+00],\n",
       "          [ 2.2471e+00, -1.9397e+00,  2.1372e-01,  ...,  2.3520e+00,\n",
       "            9.8914e-01, -5.1729e-01],\n",
       "          [ 1.4531e+00, -1.7124e+00, -6.3771e-01,  ...,  1.0426e+00,\n",
       "           -3.4710e-01, -1.0703e+00]],\n",
       "\n",
       "         [[-8.2453e-02, -1.3474e-01, -3.8441e-02,  ..., -1.7972e-01,\n",
       "           -1.3714e-01,  1.2793e-01],\n",
       "          [ 1.1564e+00,  1.2605e-01,  1.6017e+00,  ..., -7.3819e-03,\n",
       "           -2.5630e-01, -2.5673e-01],\n",
       "          [-2.9368e-01,  1.5745e+00, -4.6649e-01,  ...,  1.3715e+00,\n",
       "            7.6680e-01,  3.1742e-01],\n",
       "          [-2.2014e+00, -2.0186e-01, -5.0556e-01,  ...,  4.5407e-01,\n",
       "           -1.9211e-02, -4.7583e-01],\n",
       "          [-3.8468e-01, -1.0407e-01,  1.4439e-01,  ..., -1.8501e-01,\n",
       "            4.8258e-01, -6.5645e-01],\n",
       "          [-3.4725e-01, -1.0620e+00, -3.0910e-01,  ..., -3.7128e-02,\n",
       "           -2.7428e-01, -5.4184e-01]],\n",
       "\n",
       "         [[-3.6739e-02, -2.9450e-02,  9.2723e-02,  ...,  8.0920e-02,\n",
       "           -3.5601e-02,  2.1601e-02],\n",
       "          [-3.1054e-01,  2.0403e-01, -7.4490e-01,  ..., -5.1290e-01,\n",
       "           -3.6873e-01,  4.8678e-01],\n",
       "          [ 2.2311e-01,  5.1405e-02, -8.0553e-01,  ..., -1.2504e+00,\n",
       "           -3.9416e-01, -3.3045e-03],\n",
       "          [ 1.3709e+00,  1.0330e-01, -1.2118e+00,  ..., -1.1365e+00,\n",
       "           -1.6229e+00,  5.1408e-01],\n",
       "          [ 1.0135e+00,  1.2860e+00, -2.7066e-01,  ...,  5.4860e-01,\n",
       "            3.8029e-01,  3.1228e-01],\n",
       "          [-1.7913e+00,  3.0682e-01, -1.3673e+00,  ...,  1.0831e+00,\n",
       "            7.4494e-01,  6.0202e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-3.2049e-01,  8.6885e-01, -1.5324e-01,  ...,  1.1211e+00,\n",
       "           -1.6430e-01,  1.3775e-01],\n",
       "          [-3.1072e-01, -3.8682e+00, -5.8579e-02,  ..., -3.6616e+00,\n",
       "            2.0223e+00,  1.2416e+00],\n",
       "          [ 5.8630e-02, -2.9214e+00, -3.4584e-01,  ..., -3.6319e+00,\n",
       "            4.8251e-01,  1.7350e+00],\n",
       "          [ 4.1428e-01, -3.4519e+00, -4.2520e-01,  ..., -3.8489e+00,\n",
       "           -2.8877e-02,  1.0188e+00],\n",
       "          [-4.6318e-01, -2.5432e+00, -2.7518e-01,  ..., -3.9862e+00,\n",
       "            1.6693e-01,  1.4209e+00],\n",
       "          [ 1.3069e+00, -3.4412e+00,  3.0471e-01,  ..., -4.0085e+00,\n",
       "            1.2313e+00,  1.0717e+00]],\n",
       "\n",
       "         [[ 4.0810e-02,  8.5320e-01, -6.3841e-01,  ..., -1.5343e-02,\n",
       "            3.0190e-01,  5.2733e-03],\n",
       "          [ 4.6215e-01,  8.6869e-01,  2.6022e-01,  ...,  1.7123e+00,\n",
       "           -1.0823e+00, -3.2908e-01],\n",
       "          [-5.0825e-01,  8.0362e-01,  6.1611e-01,  ...,  1.1413e+00,\n",
       "           -5.5813e-01,  1.4274e-02],\n",
       "          [-2.1603e+00,  1.5900e-01,  4.4649e-01,  ...,  1.9910e+00,\n",
       "            2.6376e-01,  1.2486e-02],\n",
       "          [-1.4328e+00,  8.6239e-03,  1.2210e+00,  ...,  1.5794e+00,\n",
       "            4.7818e-01,  2.2866e-01],\n",
       "          [ 5.1970e-01, -3.0334e-01,  1.0713e+00,  ...,  2.2699e-01,\n",
       "           -9.2281e-02,  5.1060e-01]],\n",
       "\n",
       "         [[-3.1140e-01,  1.3949e-01, -9.9361e-01,  ..., -3.4513e-01,\n",
       "           -5.1840e-02, -1.4352e-01],\n",
       "          [ 7.1280e-01, -4.1136e-02,  2.9424e+00,  ...,  7.9545e-01,\n",
       "            1.4838e-01,  5.0909e-02],\n",
       "          [ 4.2372e-01, -1.9120e-01,  3.7049e+00,  ...,  3.6336e-01,\n",
       "           -1.5386e+00,  1.8186e-01],\n",
       "          [-8.1924e-01,  6.6715e-01,  1.7990e+00,  ...,  6.4897e-01,\n",
       "           -4.3933e-01,  9.6889e-01],\n",
       "          [ 7.8912e-01, -1.1956e-01,  3.0117e+00,  ...,  8.6560e-01,\n",
       "            3.1553e-02, -1.2871e-01],\n",
       "          [ 2.2419e-01,  1.0103e+00,  1.7612e+00,  ...,  9.4708e-01,\n",
       "            6.8134e-01,  3.2676e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 3.7173e-01,  8.6853e-02, -5.9646e-02,  ..., -4.3355e-02,\n",
       "            2.2932e-01,  1.3419e-02],\n",
       "          [-1.8669e+00,  1.7222e+00,  1.9234e+00,  ..., -4.8946e-01,\n",
       "            1.0133e+00,  9.3072e-01],\n",
       "          [ 1.4514e-01,  1.3255e+00,  6.8195e-01,  ..., -1.6108e+00,\n",
       "            1.6791e-01, -1.6954e-01],\n",
       "          [-1.7796e+00, -6.5941e-01, -1.2477e+00,  ..., -3.1244e-01,\n",
       "           -6.0428e-01, -1.0209e+00],\n",
       "          [-8.5271e-01,  1.4177e+00,  1.8892e-01,  ...,  1.3179e-01,\n",
       "           -1.1821e+00,  1.2693e-01],\n",
       "          [ 2.6726e-01,  1.5470e+00,  2.4390e-01,  ..., -7.2345e-02,\n",
       "           -6.3282e-01,  1.2001e-01]],\n",
       "\n",
       "         [[ 2.1518e-01,  5.8453e-02,  3.2166e-01,  ...,  4.0896e-01,\n",
       "            1.4614e-02,  2.2547e-01],\n",
       "          [ 3.7667e-01,  9.4963e-02,  4.6621e-01,  ..., -1.6789e+00,\n",
       "            6.8594e-01, -2.6689e-01],\n",
       "          [ 1.0611e+00,  1.2183e+00,  8.2822e-01,  ..., -1.1886e+00,\n",
       "            3.5426e-01, -4.2596e-01],\n",
       "          [ 1.6141e+00,  6.7119e-01,  7.8488e-01,  ..., -1.4534e+00,\n",
       "            9.4933e-02,  6.3998e-01],\n",
       "          [-3.0142e-01, -5.7277e-01,  5.6451e-01,  ..., -8.7671e-01,\n",
       "           -1.1173e-01,  5.2868e-01],\n",
       "          [ 5.6921e-01, -1.1702e-02,  7.2559e-01,  ..., -8.9586e-01,\n",
       "            2.0268e-01,  1.0248e-01]],\n",
       "\n",
       "         [[-3.0173e+00,  5.4633e-01,  5.5436e-01,  ..., -9.4674e-01,\n",
       "            3.3480e-01,  2.0112e-01],\n",
       "          [ 6.5015e+00,  9.7020e-01, -1.7804e+00,  ...,  1.2424e+00,\n",
       "           -8.3713e-01,  4.8234e-01],\n",
       "          [ 7.4352e+00, -8.0394e-01, -2.7683e+00,  ...,  1.5169e+00,\n",
       "           -4.0172e-01,  1.2150e-01],\n",
       "          [ 7.3777e+00,  2.3257e-01, -2.8249e+00,  ...,  2.4765e+00,\n",
       "            6.7907e-01,  5.4506e-01],\n",
       "          [ 7.4857e+00,  4.8429e-01, -1.4778e+00,  ...,  1.3101e+00,\n",
       "           -6.9242e-01, -1.1938e+00],\n",
       "          [ 7.7763e+00, -5.5446e-01, -1.3705e+00,  ...,  2.4330e+00,\n",
       "           -8.2500e-01, -6.8445e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 4.3228e-02, -5.6327e-02,  1.2557e-02,  ..., -6.4996e-02,\n",
       "            2.1494e-03, -9.7407e-02],\n",
       "          [-3.0446e-01, -7.1082e-01, -5.4701e-01,  ..., -8.1879e-01,\n",
       "           -7.4085e-02,  3.3871e-01],\n",
       "          [ 1.3923e-01,  1.5701e-02, -5.4605e-01,  ..., -5.2265e-02,\n",
       "           -5.2465e-02,  6.0907e-01],\n",
       "          [ 4.3496e-01, -8.6741e-01,  2.2354e-02,  ...,  5.8451e-01,\n",
       "            3.3674e-02, -2.0087e-01],\n",
       "          [-1.0235e-01, -1.2183e+00,  2.1104e-01,  ...,  3.2353e-01,\n",
       "            7.5239e-01, -2.5378e-01],\n",
       "          [ 1.5369e-01, -2.4151e-01, -5.7234e-01,  ..., -6.7632e-01,\n",
       "            3.4478e-01, -9.6583e-01]],\n",
       "\n",
       "         [[ 6.4710e-02,  2.3848e-02, -1.6738e-02,  ..., -3.5923e-02,\n",
       "            6.8741e-04, -9.7012e-03],\n",
       "          [-1.1435e-01, -1.8268e-01, -1.5471e+00,  ...,  1.1490e+00,\n",
       "           -4.3846e-01,  1.3519e-01],\n",
       "          [ 2.9449e-01,  6.2970e-01,  3.1251e-01,  ..., -3.9533e-01,\n",
       "            4.6601e-01, -2.5856e-01],\n",
       "          [ 5.1238e-01,  5.5972e-02, -3.8652e-01,  ..., -5.0439e-01,\n",
       "           -3.1435e-01, -5.2331e-01],\n",
       "          [ 2.7124e-01, -8.2191e-01, -2.6195e+00,  ...,  4.7203e-01,\n",
       "           -1.4810e+00,  8.5465e-02],\n",
       "          [ 5.1512e-01, -3.1385e-01, -1.1469e-01,  ..., -5.8062e-01,\n",
       "           -5.2694e-01,  9.4743e-02]],\n",
       "\n",
       "         [[ 7.1990e-02,  1.6949e-02, -5.3191e-03,  ...,  2.7666e-02,\n",
       "           -6.0538e-02, -6.7320e-02],\n",
       "          [-1.7682e-01,  5.2578e-01, -9.7051e-01,  ..., -6.6440e-01,\n",
       "            5.5119e-01, -4.4782e-02],\n",
       "          [-2.3683e-01, -4.7106e-01, -4.9434e-01,  ..., -1.0963e+00,\n",
       "            8.2499e-01,  1.8725e+00],\n",
       "          [-8.5253e-01, -1.5318e-01,  9.2394e-01,  ...,  4.9895e-01,\n",
       "            6.8942e-01,  1.9823e-01],\n",
       "          [-2.8039e-01,  5.1057e-01, -1.7782e+00,  ...,  4.9202e-01,\n",
       "            7.9970e-01, -9.5051e-01],\n",
       "          [ 9.0017e-01,  1.2445e-01, -3.0099e-01,  ...,  2.2833e-02,\n",
       "           -1.8735e-01, -4.6207e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 6.6573e-03,  3.0446e-02,  3.0389e-02,  ..., -7.6937e-02,\n",
       "           -2.6515e-02,  2.3494e-02],\n",
       "          [-8.3228e-01, -9.6466e-01,  2.1691e-01,  ...,  1.1708e+00,\n",
       "            7.3502e-03,  5.3843e-01],\n",
       "          [-4.5923e-01, -1.0111e+00,  1.4878e+00,  ..., -1.0663e-01,\n",
       "           -2.5414e-03, -9.0904e-01],\n",
       "          [-9.7143e-01,  2.2295e-01, -8.8649e-01,  ...,  1.5974e+00,\n",
       "           -1.1798e+00,  8.4095e-01],\n",
       "          [ 2.9283e-01, -5.9390e-01,  4.1220e-01,  ...,  9.2742e-01,\n",
       "           -7.1390e-01,  9.0997e-01],\n",
       "          [ 4.1530e-02, -8.2285e-01, -2.1473e-01,  ...,  5.3071e-02,\n",
       "            1.0171e+00,  6.6470e-01]],\n",
       "\n",
       "         [[ 4.5511e-02, -2.0962e-02,  1.9592e-02,  ...,  2.7622e-02,\n",
       "           -8.2191e-04,  9.0174e-03],\n",
       "          [ 1.0913e-01, -1.4601e-01, -2.1051e+00,  ..., -2.6000e-02,\n",
       "            5.4049e-01, -3.9601e-01],\n",
       "          [-1.1434e+00, -4.1603e-01, -1.4997e+00,  ..., -1.4142e-01,\n",
       "           -5.8704e-01,  1.7065e+00],\n",
       "          [ 3.1159e-01,  7.5917e-01, -6.0320e-01,  ...,  8.7181e-01,\n",
       "           -6.5717e-01,  3.7381e-01],\n",
       "          [-1.1317e+00,  5.4180e-01,  2.8922e-01,  ..., -6.1929e-01,\n",
       "            1.0396e-02,  7.9392e-01],\n",
       "          [-1.3432e+00,  2.0952e-01, -2.4496e+00,  ...,  1.1622e-01,\n",
       "            1.3808e+00, -5.9271e-01]],\n",
       "\n",
       "         [[ 7.0952e-02, -1.9478e-01, -6.7487e-02,  ..., -3.3066e-02,\n",
       "            1.9585e-01, -5.4065e-02],\n",
       "          [ 1.2149e-01, -4.6858e-01, -5.1993e-01,  ...,  6.9780e-01,\n",
       "           -7.3727e-01, -6.3904e-02],\n",
       "          [ 2.9625e-01,  6.8001e-01, -3.4576e-01,  ..., -7.3443e-01,\n",
       "           -3.0156e-01,  4.3749e-01],\n",
       "          [-5.8476e-01,  1.0210e-01, -1.7300e-01,  ..., -2.7738e-02,\n",
       "           -3.2456e-01,  4.4014e-01],\n",
       "          [-4.0677e-02, -1.2849e-01, -1.8215e-01,  ..., -5.9535e-01,\n",
       "           -5.3083e-01,  1.7815e-02],\n",
       "          [-4.7359e-01, -8.7440e-01, -3.1209e-01,  ..., -8.4427e-01,\n",
       "           -1.9417e-01, -1.2227e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 1.0598, -0.2576, -0.1330,  ...,  0.6275,  0.7200, -0.2931],\n",
       "          [-3.0010, -2.0994,  0.8817,  ...,  1.2329, -5.4343,  0.7509],\n",
       "          [-3.9601, -1.0593,  1.9254,  ...,  1.4743, -4.8834,  0.7850],\n",
       "          [-3.6584, -2.5969,  1.1058,  ..., -0.6667, -5.5465,  0.5255],\n",
       "          [-5.3856, -3.4743,  3.1302,  ..., -0.4472, -4.3242,  0.4407],\n",
       "          [-3.3996, -2.3864,  0.5576,  ..., -0.4880, -3.6606, -0.6552]],\n",
       "\n",
       "         [[-0.1414, -0.0703,  0.1629,  ..., -0.0395, -0.8804, -0.1992],\n",
       "          [ 0.6764, -0.1061, -0.2575,  ...,  1.0931, -0.3259, -1.3441],\n",
       "          [ 0.7754,  1.2517,  0.7288,  ..., -0.0374,  0.1500,  2.3914],\n",
       "          [-1.0990,  0.0501,  0.8400,  ...,  0.0947, -0.3824,  1.4921],\n",
       "          [ 2.0131, -1.1281,  2.3699,  ..., -0.2338, -0.6390,  0.6200],\n",
       "          [ 1.4729, -0.4306,  0.3493,  ..., -1.5473, -0.6777,  0.1039]],\n",
       "\n",
       "         [[ 0.1872,  0.2999,  1.1238,  ..., -0.4582,  0.4404, -0.4976],\n",
       "          [-0.6192, -2.2502, -2.7386,  ..., -1.2659, -1.1625,  2.0010],\n",
       "          [-0.1949, -2.0305, -0.6882,  ..., -0.2601, -1.4730,  2.7293],\n",
       "          [ 0.4866, -1.3215, -1.2277,  ..., -0.5468, -0.5775,  2.1010],\n",
       "          [-0.1648, -1.7379, -2.2976,  ..., -1.0136, -0.1060,  1.9560],\n",
       "          [ 1.0007, -1.2073, -2.6906,  ..., -1.5179, -0.8087,  2.8902]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1452,  0.0756, -0.2231,  ...,  0.0079,  0.1399,  0.0327],\n",
       "          [-1.1117, -1.3187, -0.5807,  ...,  1.7499, -1.9428, -0.2632],\n",
       "          [-1.5655, -0.5388,  0.5272,  ..., -0.7323,  0.3373, -0.8425],\n",
       "          [-1.4299, -0.7899,  0.7158,  ...,  1.5957, -0.1638, -1.1983],\n",
       "          [-0.2966, -0.8917, -0.7289,  ...,  0.4857, -1.2439, -1.6168],\n",
       "          [-0.5506,  0.9766, -0.0857,  ...,  0.3817, -1.2079, -2.0515]],\n",
       "\n",
       "         [[-0.3549, -2.1863,  0.1139,  ..., -0.0866, -0.0449,  0.9256],\n",
       "          [-0.1606,  3.1117,  0.6354,  ..., -0.4114, -0.6871, -0.2264],\n",
       "          [-0.9946,  1.4344,  0.3960,  ...,  0.8561, -1.1025,  0.9436],\n",
       "          [-0.0799,  3.5233,  1.1360,  ...,  1.4720, -0.3455,  0.4812],\n",
       "          [ 0.4755,  3.0802,  0.8688,  ...,  0.2543, -0.9928, -1.1895],\n",
       "          [ 0.4240,  1.1136, -0.7988,  ..., -0.0236, -2.1793,  1.1526]],\n",
       "\n",
       "         [[ 0.3709,  0.0660, -0.1260,  ...,  0.6461,  0.1352,  0.2647],\n",
       "          [-0.0615, -0.4618, -0.9971,  ..., -1.1048,  0.5394, -0.4756],\n",
       "          [ 0.8462, -0.1020, -0.3251,  ...,  0.0526,  0.0439, -0.0495],\n",
       "          [-1.5956,  0.3087, -1.9698,  ...,  0.3846,  0.6206, -0.0098],\n",
       "          [-1.5274,  1.9475, -0.9254,  ..., -0.2141,  0.8091,  1.0167],\n",
       "          [-1.1496,  2.0702,  1.2470,  ..., -0.7815,  0.9233,  0.0988]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[-4.5227e-02,  4.8290e-02, -6.4662e-02,  ..., -2.6433e-02,\n",
       "           -4.9069e-03,  2.7710e-02],\n",
       "          [-2.2477e-01, -3.1940e-01,  1.5452e-01,  ...,  1.6907e-02,\n",
       "           -4.1428e-01, -6.1791e-01],\n",
       "          [ 3.4222e-01, -1.4304e+00, -9.6565e-01,  ...,  5.9811e-01,\n",
       "            7.2143e-01,  5.7869e-01],\n",
       "          [-4.1886e-01, -3.8541e-01, -5.6222e-01,  ..., -2.6128e-01,\n",
       "            1.1809e-02,  2.6540e-01],\n",
       "          [-2.1254e-01, -3.9118e-02,  3.8152e-01,  ...,  9.3659e-02,\n",
       "           -4.1416e-01,  3.4439e-01],\n",
       "          [-7.7631e-01,  9.0602e-01,  8.9448e-02,  ..., -5.2875e-01,\n",
       "            3.1061e-01, -2.1362e-01]],\n",
       "\n",
       "         [[ 2.7121e-03, -2.2894e-02,  2.8224e-02,  ...,  1.7317e-02,\n",
       "           -4.9944e-02,  1.8770e-02],\n",
       "          [-2.6921e-01, -8.8029e-01, -1.0514e+00,  ...,  1.1528e+00,\n",
       "           -7.3253e-01, -7.4207e-01],\n",
       "          [ 3.0824e-01, -4.0436e-01, -2.1131e+00,  ...,  5.3669e-01,\n",
       "           -1.8250e+00, -4.0121e-01],\n",
       "          [ 1.9536e+00, -1.1145e+00, -6.1318e-01,  ...,  1.3025e+00,\n",
       "           -1.0928e+00, -3.9113e-01],\n",
       "          [ 1.1448e+00, -7.0413e-01,  1.6109e-02,  ...,  2.0370e+00,\n",
       "            1.5034e-01, -2.9063e-01],\n",
       "          [ 8.9381e-01,  2.1161e-01, -1.6927e-01,  ...,  1.2482e+00,\n",
       "            3.0207e-01, -2.4404e-01]],\n",
       "\n",
       "         [[ 3.9054e-02, -2.8235e-02,  5.0748e-02,  ...,  3.5171e-02,\n",
       "            1.2897e-04,  9.7119e-03],\n",
       "          [ 1.0363e+00, -3.0174e-01,  2.0444e-01,  ..., -7.7884e-01,\n",
       "           -7.6941e-01, -4.9696e-01],\n",
       "          [-1.0197e+00, -8.0067e-01, -1.0989e+00,  ...,  1.0367e+00,\n",
       "            7.3754e-01, -1.6985e-01],\n",
       "          [ 8.0481e-01,  4.1566e-01,  1.5628e+00,  ..., -3.3388e-01,\n",
       "           -6.9447e-01,  4.8915e-01],\n",
       "          [-1.1871e+00,  6.6517e-01,  1.2948e+00,  ..., -3.5233e-01,\n",
       "            8.4082e-01,  9.1417e-01],\n",
       "          [-6.9144e-02, -1.7536e+00,  3.1743e-01,  ..., -1.2524e+00,\n",
       "           -5.0229e-01,  5.4878e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.7761e-01,  1.0062e-01,  5.4821e-02,  ...,  4.3696e-02,\n",
       "            4.4608e-02, -1.4048e-01],\n",
       "          [-3.1825e-01,  2.5792e-01, -1.0489e+00,  ..., -9.3978e-01,\n",
       "            8.8387e-01, -1.5461e-01],\n",
       "          [-2.7823e-01, -6.7233e-01, -2.0516e-01,  ..., -3.2960e-03,\n",
       "            1.4420e+00,  2.3441e-01],\n",
       "          [ 4.6539e-01, -7.8508e-01, -2.1927e-01,  ...,  8.6783e-01,\n",
       "            4.6678e-01,  4.4633e-01],\n",
       "          [ 3.8866e-01, -1.2830e+00, -9.8386e-01,  ..., -8.6975e-02,\n",
       "            1.5559e+00,  4.2572e-01],\n",
       "          [-9.9100e-03,  5.3731e-01, -2.7283e-01,  ...,  4.4924e-01,\n",
       "            1.3025e+00,  8.1625e-01]],\n",
       "\n",
       "         [[-5.7951e-01,  4.1325e-03,  4.4684e-02,  ..., -1.9671e-02,\n",
       "            1.7462e-02, -1.2318e-02],\n",
       "          [-1.0182e+00, -7.6491e-01,  1.6937e-01,  ...,  5.1260e-01,\n",
       "           -3.0370e-01, -1.7466e-01],\n",
       "          [ 2.4725e-01, -1.8640e-01, -7.1399e-01,  ...,  9.1625e-01,\n",
       "           -4.4038e-02,  3.7427e-01],\n",
       "          [-2.3099e+00,  1.1124e+00,  1.3478e+00,  ..., -6.9739e-01,\n",
       "            9.0182e-02, -6.0034e-01],\n",
       "          [-9.2212e-01,  3.3223e-02,  7.6564e-01,  ...,  1.0015e+00,\n",
       "           -1.5827e+00,  1.4176e+00],\n",
       "          [-2.2077e+00, -2.8421e-02, -2.4154e-01,  ...,  3.4138e-01,\n",
       "            2.2821e-01,  6.1827e-01]],\n",
       "\n",
       "         [[ 8.2133e-04,  9.1022e-02, -5.8738e-02,  ...,  6.6123e-02,\n",
       "            3.3556e-02, -3.5006e-02],\n",
       "          [-1.0060e+00,  8.2521e-01,  5.6933e-01,  ...,  8.9609e-01,\n",
       "           -1.1917e+00, -1.4758e-01],\n",
       "          [-2.9070e-01, -1.9055e-01, -8.3911e-01,  ...,  2.6314e-02,\n",
       "           -1.9105e+00, -5.1061e-01],\n",
       "          [-1.3285e-01, -4.1207e-01, -3.2695e-01,  ..., -8.7604e-01,\n",
       "           -7.7685e-01, -1.7083e+00],\n",
       "          [ 1.1618e+00,  8.8819e-01,  1.2428e+00,  ...,  6.5419e-01,\n",
       "           -5.3876e-01, -2.8056e-01],\n",
       "          [-5.6743e-01, -4.1900e-01, -1.4858e-01,  ..., -7.3187e-01,\n",
       "           -9.8117e-01,  7.8166e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-0.0356, -2.3334,  0.1628,  ..., -0.2301, -0.2022,  0.0733],\n",
       "          [ 0.1151,  5.5866,  1.0795,  ...,  1.0472, -0.8926, -0.1555],\n",
       "          [ 0.0469,  4.7817,  1.3158,  ...,  0.0144, -1.0981, -0.3126],\n",
       "          [-0.7135,  4.8839,  0.1908,  ..., -0.3973, -0.4781,  0.7263],\n",
       "          [-0.1256,  5.9513,  1.3428,  ...,  0.2039, -1.0385,  0.7661],\n",
       "          [-1.0418,  4.0440,  0.5317,  ..., -0.8926, -0.6110,  0.0318]],\n",
       "\n",
       "         [[-0.8138,  0.2279,  0.4725,  ..., -0.5224,  1.0650,  1.1247],\n",
       "          [ 1.6557,  0.0917,  2.0301,  ...,  0.4775,  1.8952, -1.0449],\n",
       "          [ 0.3102, -0.3292,  1.5251,  ...,  0.3958,  1.5547,  0.2899],\n",
       "          [ 0.8051,  0.2731,  1.6125,  ...,  1.5742,  1.2273,  0.6481],\n",
       "          [ 0.4363,  0.6966,  0.5675,  ...,  1.5033,  2.2157, -1.4228],\n",
       "          [ 1.1314,  0.0405,  0.8033,  ...,  0.5245,  2.2615,  0.8895]],\n",
       "\n",
       "         [[-0.8506,  0.4658,  0.0228,  ...,  0.4948, -0.2319,  1.1542],\n",
       "          [ 0.8886, -1.7748,  0.8340,  ...,  0.0198,  0.9573,  0.1544],\n",
       "          [ 0.9285, -0.1561,  0.7713,  ...,  0.3391,  0.8514, -0.4550],\n",
       "          [ 1.7577,  0.0898,  0.1681,  ...,  0.7189,  0.0932,  0.7510],\n",
       "          [ 1.5553, -1.4991,  0.1358,  ..., -0.4965,  0.3133,  0.2213],\n",
       "          [-0.7679, -0.7230,  0.1429,  ...,  0.0562,  0.0863,  0.5592]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.3103, -0.1343,  0.1380,  ...,  0.1847,  1.7372, -2.8672],\n",
       "          [-0.3377, -3.1372, -1.0426,  ..., -0.4304, -5.2223,  5.2024],\n",
       "          [-0.6692, -1.6247, -0.0786,  ..., -1.1782, -3.3100,  4.0057],\n",
       "          [-1.2046, -0.5717,  0.1518,  ..., -0.1885, -3.1066,  4.0446],\n",
       "          [-0.1273, -2.4571,  0.0878,  ...,  0.2198, -4.6915,  5.0691],\n",
       "          [-0.5969, -2.3509, -0.0412,  ..., -0.8095, -4.9517,  5.5058]],\n",
       "\n",
       "         [[ 0.1826,  0.3627,  0.2355,  ..., -0.2199,  0.0286, -0.1428],\n",
       "          [-1.6439, -0.0190, -0.1487,  ...,  1.2144,  0.3048,  0.1315],\n",
       "          [-1.3061, -0.8817, -0.8932,  ..., -0.5860,  0.1718,  0.5706],\n",
       "          [-1.5142,  0.5199, -1.0975,  ...,  0.1138, -0.4236, -0.7524],\n",
       "          [-1.4080,  1.7923, -1.3060,  ...,  0.7760,  1.0981, -0.0817],\n",
       "          [-0.7504,  0.7739, -0.2131,  ...,  2.4990, -0.1166,  0.6092]],\n",
       "\n",
       "         [[ 0.3655,  0.1136,  0.6105,  ...,  0.5283,  0.5772, -0.3373],\n",
       "          [-1.1060, -1.0345, -2.1134,  ..., -0.2591, -3.7615,  0.1058],\n",
       "          [ 0.3500, -0.4193,  0.0443,  ..., -1.5698, -3.8746,  0.4801],\n",
       "          [ 0.9552,  0.0268, -0.7750,  ...,  0.4981, -3.4582,  0.7137],\n",
       "          [ 0.4888, -1.1961,  0.7144,  ..., -0.3354, -4.3237,  0.4186],\n",
       "          [ 0.7639, -0.4656, -0.2945,  ..., -0.4981, -4.4399, -0.1717]]]],\n",
       "       grad_fn=<PermuteBackward0>), tensor([[[[ 5.7473e-02, -8.5153e-03, -1.8815e-02,  ...,  1.2536e-01,\n",
       "           -7.3760e-02, -2.9692e-02],\n",
       "          [-1.6788e+00,  2.9579e-01,  6.2357e-01,  ...,  5.5226e-01,\n",
       "            1.5418e+00,  6.2661e-01],\n",
       "          [-1.2540e+00, -1.8016e-01, -1.5737e-01,  ..., -1.0715e-01,\n",
       "           -2.6360e-01,  3.2832e-01],\n",
       "          [-1.4670e+00, -8.3560e-01,  1.7811e-02,  ..., -3.9449e-01,\n",
       "           -2.2040e-01,  2.0716e-01],\n",
       "          [-3.6410e+00,  1.0386e+00,  2.8591e-01,  ...,  1.0004e+00,\n",
       "            3.5254e-01, -1.2106e-01],\n",
       "          [-1.6441e+00,  3.4731e-01, -2.1423e-01,  ...,  4.8709e-01,\n",
       "           -1.2243e+00,  2.8440e-01]],\n",
       "\n",
       "         [[ 4.4748e-03,  3.8178e-02,  4.7241e-02,  ..., -7.0020e-03,\n",
       "           -3.6897e-03, -4.8701e-03],\n",
       "          [-2.8389e-01, -1.3513e+00, -1.8211e-01,  ...,  5.6872e-02,\n",
       "            3.3444e-01,  1.0720e+00],\n",
       "          [ 9.2677e-01, -1.2269e+00, -7.3231e-01,  ...,  7.8457e-01,\n",
       "            2.3795e-01,  5.9645e-01],\n",
       "          [-2.3686e-02, -2.1644e-01,  1.8048e-01,  ...,  9.5573e-01,\n",
       "            7.9543e-01, -8.7129e-01],\n",
       "          [ 1.0764e+00,  8.4784e-01, -1.1386e+00,  ..., -7.0202e-01,\n",
       "           -6.5605e-02,  3.1341e-01],\n",
       "          [ 2.8365e-01, -2.3898e-01, -8.4473e-01,  ..., -5.4331e-01,\n",
       "           -1.0731e+00,  1.3455e-01]],\n",
       "\n",
       "         [[ 4.4921e-02, -3.5515e-02,  6.1401e-02,  ...,  4.1851e-02,\n",
       "           -7.0526e-02, -7.1356e-02],\n",
       "          [-7.7282e-01,  6.5997e-01,  8.1298e-01,  ..., -5.6638e-01,\n",
       "            3.9235e-01,  1.0096e-01],\n",
       "          [ 5.8819e-01, -5.3685e-01, -1.1612e+00,  ...,  9.8606e-02,\n",
       "            6.1461e-01,  2.7073e-01],\n",
       "          [-2.3873e-01, -3.2745e-01,  7.4255e-02,  ..., -3.8094e-01,\n",
       "            2.7798e-01,  1.1014e-01],\n",
       "          [ 3.9456e-01,  8.1709e-01, -2.0648e-01,  ..., -1.2925e+00,\n",
       "           -6.0640e-01, -2.7089e-01],\n",
       "          [-1.4372e+00, -4.4136e-01,  1.5934e-01,  ...,  3.4152e-02,\n",
       "           -1.2438e+00, -4.4878e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.7330e-02, -4.3363e-02,  3.1087e-02,  ..., -8.5323e-02,\n",
       "            2.6670e-02,  3.6327e-03],\n",
       "          [ 7.8037e-01,  6.8606e-01,  2.2174e+00,  ...,  1.0148e-01,\n",
       "           -1.7618e-01, -1.5259e+00],\n",
       "          [ 6.6088e-01, -1.6237e-02,  9.2152e-01,  ...,  7.7460e-02,\n",
       "           -4.2678e-01, -7.0956e-01],\n",
       "          [ 8.3168e-01,  5.9163e-03, -1.6475e+00,  ..., -1.0886e+00,\n",
       "           -3.7256e-01, -1.3091e+00],\n",
       "          [ 1.1089e+00,  9.5406e-01,  3.6294e-01,  ...,  1.0125e+00,\n",
       "           -1.7784e+00, -6.0580e-01],\n",
       "          [ 1.8331e-01,  8.1281e-01,  1.7401e+00,  ...,  1.5922e-01,\n",
       "           -1.4555e+00, -7.4584e-01]],\n",
       "\n",
       "         [[ 1.4321e-01, -6.1989e-02,  1.2159e-01,  ...,  6.0080e-02,\n",
       "            2.7646e-02, -1.3817e-01],\n",
       "          [-9.9824e-01,  4.7822e-01, -4.5062e-01,  ...,  3.5486e-01,\n",
       "           -4.8685e-01, -4.2823e-01],\n",
       "          [ 7.0377e-01,  9.9592e-02,  1.1207e+00,  ...,  1.0377e+00,\n",
       "           -1.1176e+00,  1.7990e-01],\n",
       "          [ 1.7018e-01, -4.4680e-02, -2.3843e-01,  ..., -4.5429e-01,\n",
       "           -1.9244e+00, -7.2311e-01],\n",
       "          [-8.7526e-01,  1.0130e+00,  4.6512e-01,  ...,  5.0754e-01,\n",
       "           -2.4088e+00,  7.6891e-01],\n",
       "          [-1.6606e+00, -8.2408e-01, -3.9554e-01,  ..., -2.5542e-01,\n",
       "            1.5176e-01,  7.1257e-01]],\n",
       "\n",
       "         [[ 2.0354e-01, -4.6145e-02, -5.0557e-02,  ...,  3.8320e-02,\n",
       "            5.3432e-02,  1.3004e-02],\n",
       "          [-1.8151e-01, -8.6567e-01,  1.1603e+00,  ..., -1.8299e-01,\n",
       "           -2.8802e-01,  6.7206e-01],\n",
       "          [ 2.2950e-02,  6.5368e-01,  1.1950e+00,  ..., -4.9844e-01,\n",
       "           -1.7019e-01, -6.7962e-01],\n",
       "          [ 3.8678e-01,  1.5888e+00,  1.2262e+00,  ...,  9.6354e-03,\n",
       "           -4.2317e-01, -1.4818e-01],\n",
       "          [-5.6604e-02,  5.8093e-01,  1.8826e+00,  ..., -7.2838e-02,\n",
       "           -3.7797e-01,  4.4831e-01],\n",
       "          [ 5.2983e-01,  1.3952e+00,  1.3129e+00,  ..., -1.0933e-01,\n",
       "           -1.3515e-01,  1.1491e+00]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[ 3.1265e-02, -2.5827e-01, -4.4810e-01,  ...,  3.1155e-01,\n",
       "            3.1791e-01,  3.6600e-01],\n",
       "          [-1.2436e-01,  2.7715e-01,  2.3981e-03,  ...,  3.8037e-01,\n",
       "           -8.1307e-01, -1.6631e-01],\n",
       "          [ 7.8786e-01, -7.5712e-01, -1.9021e+00,  ...,  7.5112e-01,\n",
       "           -1.0269e+00, -4.0748e-01],\n",
       "          [ 1.1342e-01, -2.4919e-01, -2.4136e+00,  ..., -2.7588e-01,\n",
       "           -2.8363e-01,  5.0040e-01],\n",
       "          [ 7.9674e-01, -6.7338e-01,  1.0023e-01,  ..., -1.2403e+00,\n",
       "           -4.4778e-01,  9.7478e-01],\n",
       "          [ 6.4265e-01, -6.8296e-01, -8.4910e-01,  ..., -1.0542e-01,\n",
       "            1.1598e-01,  6.9584e-01]],\n",
       "\n",
       "         [[-2.9535e-01,  1.7390e-01,  1.2345e-01,  ...,  3.5688e-02,\n",
       "           -1.1505e+00, -1.4689e-01],\n",
       "          [-1.1355e-01, -4.1412e-01,  9.1290e-01,  ...,  9.6654e-01,\n",
       "            5.8453e-01, -7.4424e-01],\n",
       "          [ 4.5874e-01, -8.6288e-01, -2.0145e-01,  ..., -8.2058e-02,\n",
       "           -1.6157e+00,  1.1296e+00],\n",
       "          [-6.2258e-02,  5.3364e-02,  1.4471e-01,  ..., -7.1583e-02,\n",
       "           -1.6341e+00, -1.1101e-01],\n",
       "          [-6.9057e-01,  4.6543e-01,  4.5647e-01,  ..., -2.7789e+00,\n",
       "           -8.7772e-01, -8.0286e-01],\n",
       "          [-1.4687e+00,  5.3993e-01, -3.5032e-01,  ..., -4.7708e-01,\n",
       "            2.9387e+00, -4.3536e-02]],\n",
       "\n",
       "         [[-1.2362e+00, -9.9565e-02,  5.5463e-01,  ..., -6.7408e-01,\n",
       "            4.5997e-01, -2.8416e-01],\n",
       "          [ 2.0954e+00, -1.3990e-01,  7.3124e-01,  ..., -3.2082e-01,\n",
       "            1.0775e+00, -2.4065e-01],\n",
       "          [ 2.3043e+00,  1.5166e+00,  1.6962e+00,  ...,  4.1540e-01,\n",
       "            1.0396e+00,  1.1567e+00],\n",
       "          [ 2.0218e+00,  1.3504e+00, -4.4089e-01,  ..., -2.2982e-01,\n",
       "            1.3566e+00,  1.7886e+00],\n",
       "          [ 2.8668e+00,  1.1171e-01,  4.7083e-01,  ...,  6.8968e-01,\n",
       "            2.8099e+00,  1.1740e+00],\n",
       "          [ 2.0973e+00,  7.4550e-01,  1.5603e+00,  ...,  1.5296e-01,\n",
       "            6.7995e-01,  4.5645e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 8.0139e-01, -9.0872e-01, -3.7500e-01,  ..., -1.0386e+00,\n",
       "           -4.1539e-01,  4.9724e-01],\n",
       "          [ 9.0770e-01, -1.2111e-01, -8.4732e-01,  ...,  9.6769e-01,\n",
       "            1.3616e+00, -3.7052e-01],\n",
       "          [ 1.4757e-01,  4.4035e-01, -1.2462e+00,  ...,  4.6413e-01,\n",
       "           -2.5865e-01, -1.1110e+00],\n",
       "          [ 6.1237e-01, -1.0029e+00, -4.3199e-01,  ..., -1.1188e+00,\n",
       "            5.8891e-02, -1.6851e+00],\n",
       "          [ 1.6327e+00,  2.0680e-01,  7.0871e-01,  ...,  1.7729e+00,\n",
       "            8.1708e-01, -2.6672e+00],\n",
       "          [ 9.4283e-01, -1.8316e-01, -3.9731e-01,  ...,  2.1147e+00,\n",
       "           -2.4119e-01, -7.4591e-01]],\n",
       "\n",
       "         [[-9.0799e-01,  2.5609e+00,  3.1598e-01,  ...,  3.5113e-01,\n",
       "            1.9552e+00, -5.2749e-01],\n",
       "          [ 4.0897e-01, -4.2087e+00,  7.4142e-01,  ...,  1.8592e+00,\n",
       "           -3.6450e+00,  3.1489e+00],\n",
       "          [-8.3782e-01, -2.9110e+00,  1.0655e+00,  ...,  1.6177e-01,\n",
       "           -2.4376e+00,  4.4168e-01],\n",
       "          [-7.9636e-01, -3.8199e+00,  2.3140e-01,  ..., -1.1272e+00,\n",
       "           -2.7806e+00,  5.4779e-02],\n",
       "          [-1.2766e-01, -4.2914e+00,  1.2084e+00,  ...,  1.8298e+00,\n",
       "           -4.0351e+00,  1.7956e-01],\n",
       "          [ 5.6422e-01, -2.8479e+00,  4.2383e-01,  ...,  1.1540e+00,\n",
       "           -3.7898e+00,  8.1388e-01]],\n",
       "\n",
       "         [[-2.0186e+00, -3.6276e-01, -1.1202e+00,  ..., -3.9061e-01,\n",
       "            5.2332e-02,  2.4295e-01],\n",
       "          [ 3.6482e+00,  4.0504e-01,  1.7606e+00,  ...,  2.2475e-01,\n",
       "            6.9652e-01,  7.9590e-01],\n",
       "          [ 1.8549e+00,  3.3149e-01,  9.5649e-01,  ..., -7.0337e-01,\n",
       "           -4.1790e-01, -3.8852e-01],\n",
       "          [ 2.1307e+00, -7.7832e-01,  6.7637e-01,  ..., -1.5798e+00,\n",
       "            3.0003e-01, -4.6352e-01],\n",
       "          [ 4.8996e+00, -1.3497e+00,  2.6635e+00,  ..., -9.9167e-01,\n",
       "           -3.4649e-01, -4.8394e-01],\n",
       "          [ 2.5102e+00,  8.1273e-01,  1.6708e+00,  ..., -1.4986e+00,\n",
       "           -1.7160e-01,  2.1024e-02]]]], grad_fn=<PermuteBackward0>), tensor([[[[-0.0518, -0.0824,  0.0109,  ...,  0.1166, -0.0293,  0.0300],\n",
       "          [ 0.4714,  1.1114,  0.5449,  ...,  0.5099,  0.3137,  1.1357],\n",
       "          [ 1.2934, -0.6187,  0.4980,  ..., -0.6826, -0.2112, -1.2719],\n",
       "          [-1.7222,  0.9565,  0.3823,  ...,  0.0704,  0.3645,  0.9828],\n",
       "          [-0.6087,  0.9181,  0.4195,  ..., -0.9411, -0.0944, -1.0075],\n",
       "          [-0.3764, -0.5113, -0.1698,  ...,  1.9759, -0.9378, -0.5659]],\n",
       "\n",
       "         [[ 0.0312,  0.0047, -0.0318,  ...,  0.0226,  0.0216,  0.0414],\n",
       "          [-0.3388, -0.2246, -0.3213,  ..., -0.0098, -0.5364, -0.6965],\n",
       "          [ 0.6231,  1.6260,  1.0083,  ...,  0.3280,  0.0851,  1.1868],\n",
       "          [-1.7301,  0.9257,  0.6053,  ...,  0.9170,  0.2242,  0.4711],\n",
       "          [-0.1977, -1.1492,  0.6887,  ...,  1.3499, -0.7797, -1.0949],\n",
       "          [-0.7037, -1.0039, -0.0853,  ...,  1.0054,  0.9327, -0.0719]],\n",
       "\n",
       "         [[ 0.0433,  0.0428, -0.0758,  ...,  0.0160, -0.0126,  0.0069],\n",
       "          [ 1.0153,  0.3589,  0.5653,  ...,  0.6469, -0.5042,  0.1156],\n",
       "          [ 0.3686,  0.6701,  0.4247,  ...,  0.1171,  0.3216,  1.0551],\n",
       "          [ 1.4072, -0.6921,  1.3340,  ..., -0.7515, -1.1917, -0.4817],\n",
       "          [ 2.4347, -1.3258,  1.4402,  ..., -0.9345,  0.6343,  0.6366],\n",
       "          [-0.1647,  0.0067, -0.3550,  ...,  0.9372, -0.2434,  0.6524]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0108,  0.0252,  0.0080,  ..., -0.0136, -0.0114,  0.0384],\n",
       "          [ 0.0987,  1.6291,  0.8300,  ...,  0.5345,  0.3531, -0.1954],\n",
       "          [-1.5649,  0.7168,  0.5145,  ...,  1.2162, -1.1439, -0.6281],\n",
       "          [-0.9088,  0.0046, -0.9472,  ...,  0.8149, -0.8037, -0.9116],\n",
       "          [ 0.2528,  0.0164,  0.9110,  ..., -0.4716,  1.0481, -0.3224],\n",
       "          [ 0.1070, -0.1562,  0.0177,  ..., -0.0383,  0.2618, -2.8896]],\n",
       "\n",
       "         [[-0.0777, -0.0462,  0.0316,  ...,  0.0174, -0.0467, -0.0949],\n",
       "          [-0.0372, -1.8648,  1.0451,  ...,  1.3321,  1.3395, -0.5499],\n",
       "          [-0.0247, -1.5505,  0.5592,  ...,  0.4743,  1.1109, -0.3644],\n",
       "          [ 1.3311, -1.9207, -1.2476,  ...,  0.3046,  1.5862, -0.1714],\n",
       "          [ 0.8577, -1.5305,  0.0127,  ...,  2.4648,  0.5663, -1.9844],\n",
       "          [ 0.4286,  1.2674,  0.7770,  ...,  2.1814,  0.2793,  1.4702]],\n",
       "\n",
       "         [[-0.0091,  0.0345, -0.0532,  ..., -0.0149,  0.0032,  0.0129],\n",
       "          [-0.4134, -0.3931,  0.0323,  ...,  0.1553,  0.7062, -0.0240],\n",
       "          [-1.1194, -1.1865,  0.3984,  ...,  1.4878,  0.4343,  0.3736],\n",
       "          [ 0.5363, -1.2161, -1.6887,  ...,  0.6120, -0.6353,  0.8151],\n",
       "          [ 0.5867, -0.0181, -0.3763,  ...,  1.6702,  1.4880,  0.8006],\n",
       "          [-0.1104, -0.9858, -1.4115,  ...,  1.3949, -0.1228,  0.4807]]]],\n",
       "       grad_fn=<PermuteBackward0>)), (tensor([[[[-5.1013e-01,  4.8267e-01, -8.4193e-01,  ..., -1.0151e+00,\n",
       "           -1.3224e+00,  2.1238e-01],\n",
       "          [ 1.5307e-01,  3.0327e-01,  3.5407e-03,  ...,  1.7348e+00,\n",
       "            2.7090e-01, -7.6402e-01],\n",
       "          [-8.3106e-01,  7.5430e-01, -1.9786e-01,  ...,  1.1467e+00,\n",
       "            3.9011e-02,  1.3111e-01],\n",
       "          [ 3.0332e-02,  1.1950e-01, -1.5980e+00,  ...,  2.9283e+00,\n",
       "           -3.0696e-01, -4.4625e-01],\n",
       "          [-1.5941e+00,  4.5251e-01, -6.8752e-01,  ...,  2.3944e+00,\n",
       "            1.4578e+00,  6.8007e-01],\n",
       "          [-3.7024e-01,  2.6031e-01, -3.1578e-01,  ...,  1.3460e+00,\n",
       "            3.5290e-01,  5.4491e-01]],\n",
       "\n",
       "         [[ 8.6592e-01, -2.0649e+00,  1.4851e-01,  ...,  2.3743e-01,\n",
       "           -2.4548e+00, -4.3184e-01],\n",
       "          [ 1.3757e+00,  1.9846e+00, -3.8502e-01,  ...,  4.2510e-01,\n",
       "            1.2671e+00,  5.4760e-01],\n",
       "          [ 5.5269e-01,  6.2882e-01,  9.2901e-01,  ...,  1.1476e+00,\n",
       "           -2.2623e+00, -1.1701e+00],\n",
       "          [ 4.2041e-01,  1.5391e+00,  7.6890e-01,  ...,  1.7536e+00,\n",
       "            8.9277e-01, -1.8969e+00],\n",
       "          [ 1.8930e+00,  1.3092e+00,  1.9426e+00,  ...,  3.0063e+00,\n",
       "            8.2550e-01,  7.8794e-01],\n",
       "          [ 2.4453e+00,  1.4432e+00, -1.3746e-01,  ..., -1.0846e-01,\n",
       "            1.9566e+00, -8.8860e-01]],\n",
       "\n",
       "         [[ 1.0091e+00,  3.8349e-01, -1.8023e-01,  ..., -8.0500e-01,\n",
       "           -1.3946e+00, -3.6163e-01],\n",
       "          [-1.5764e+00,  7.1081e-01, -1.5321e+00,  ...,  1.3257e+00,\n",
       "           -3.1287e-01, -1.1706e-01],\n",
       "          [-1.6940e+00,  3.8293e-01, -2.1189e-01,  ...,  1.4749e+00,\n",
       "           -5.2338e-02,  9.8747e-02],\n",
       "          [-5.9381e-01,  7.8974e-02,  3.1281e-01,  ...,  1.1097e+00,\n",
       "           -1.0472e-01, -1.1671e-02],\n",
       "          [-1.5759e+00,  7.6714e-03, -8.0903e-01,  ...,  1.6817e+00,\n",
       "            3.2148e-01,  2.9115e-01],\n",
       "          [ 6.6163e-01,  2.0430e-01,  1.6542e+00,  ...,  2.6872e-01,\n",
       "           -7.5071e-01, -2.9088e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 2.1900e-01, -5.6314e-01,  4.9281e-01,  ..., -6.6114e-01,\n",
       "            1.0669e+00,  2.9394e-01],\n",
       "          [ 1.3937e-01,  1.7349e+00, -4.5072e-01,  ..., -1.8941e+00,\n",
       "           -3.6176e-01, -5.9831e-01],\n",
       "          [-1.4065e+00,  8.4312e-01, -2.6278e+00,  ...,  1.9961e-01,\n",
       "           -2.4479e+00,  5.5917e-01],\n",
       "          [-1.4372e+00,  2.3240e+00, -2.2109e+00,  ..., -4.2310e-01,\n",
       "           -1.4402e+00,  1.0071e+00],\n",
       "          [-1.4787e+00,  2.1198e+00, -2.2937e+00,  ..., -4.1200e+00,\n",
       "           -2.1892e+00,  8.0235e-01],\n",
       "          [-7.4102e-01,  1.7184e-01, -5.7043e-01,  ..., -3.3405e+00,\n",
       "           -6.6777e-01,  3.4914e-01]],\n",
       "\n",
       "         [[ 2.5298e-01,  5.4257e-01,  5.4225e-01,  ...,  7.2462e-01,\n",
       "            7.2597e-02,  8.3592e-01],\n",
       "          [ 9.2174e-01,  1.8549e+00, -2.3675e-01,  ...,  9.1606e-01,\n",
       "           -3.5145e-01,  5.5535e-01],\n",
       "          [-1.7560e+00, -2.5204e-01,  7.4721e-02,  ...,  8.4375e-01,\n",
       "            6.0274e-01,  8.8183e-01],\n",
       "          [-5.8800e-01, -4.4814e-01,  4.0588e-02,  ...,  1.2251e+00,\n",
       "           -4.6984e-01,  3.9440e-01],\n",
       "          [-1.4696e+00,  1.0046e+00,  1.1006e+00,  ...,  5.8936e-01,\n",
       "            6.1532e-01,  5.3337e-01],\n",
       "          [ 6.8143e-01, -2.6473e-01,  3.8605e-01,  ..., -1.8058e-01,\n",
       "            5.0488e-01,  4.9593e-01]],\n",
       "\n",
       "         [[-7.2546e-01,  3.0209e-01, -1.5777e+00,  ..., -3.8874e-01,\n",
       "            2.2543e-01, -1.3174e+00],\n",
       "          [-4.3144e-01,  5.9780e-01, -2.9215e-01,  ...,  1.6164e+00,\n",
       "            2.7879e-01,  1.0359e+00],\n",
       "          [ 7.7814e-01, -3.4100e-02,  7.6558e-02,  ...,  2.6130e-01,\n",
       "           -1.8198e+00,  7.4805e-01],\n",
       "          [ 5.2756e-01, -1.1698e+00,  4.2160e-01,  ..., -1.8223e+00,\n",
       "           -1.6613e+00,  8.6170e-01],\n",
       "          [-7.5913e-01, -1.1789e+00,  7.9540e-01,  ..., -2.2565e+00,\n",
       "           -3.0786e-01,  1.7069e+00],\n",
       "          [ 5.2611e-01, -9.2258e-02,  2.6935e-01,  ...,  4.6991e-01,\n",
       "            8.6021e-01, -9.1636e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 7.4456e-03,  3.0595e-02, -8.0841e-02,  ...,  4.5919e-02,\n",
       "           -2.8470e-02, -8.4999e-02],\n",
       "          [-9.1080e-01,  1.1140e+00,  3.2520e-03,  ...,  2.4568e-02,\n",
       "            7.6071e-02,  7.2995e-01],\n",
       "          [ 9.1348e-01, -4.9606e-02, -1.9350e+00,  ..., -1.0994e+00,\n",
       "            6.4609e-01, -1.5480e+00],\n",
       "          [ 5.0874e-01, -1.2718e-01, -1.4176e+00,  ...,  1.3466e+00,\n",
       "            6.8930e-01,  7.3643e-01],\n",
       "          [-7.4067e-01, -1.9795e-01, -6.4990e-01,  ..., -2.7179e-01,\n",
       "            4.6860e-01, -4.2536e-02],\n",
       "          [ 1.2437e+00, -1.4406e-01,  8.2828e-01,  ..., -6.1727e-01,\n",
       "            1.0851e+00, -4.3411e-02]],\n",
       "\n",
       "         [[ 3.9132e-02,  1.5365e-03,  4.4369e-02,  ..., -2.1840e-02,\n",
       "           -1.7448e-02, -9.4516e-03],\n",
       "          [ 9.2312e-01,  8.8517e-01,  1.5586e+00,  ...,  1.0280e-01,\n",
       "           -7.6625e-03,  4.0505e-01],\n",
       "          [ 1.5077e+00, -1.9202e-01,  9.8184e-01,  ...,  4.5770e-01,\n",
       "            1.6687e+00, -5.8306e-01],\n",
       "          [-9.5162e-01,  1.2338e-01, -1.7992e-01,  ...,  9.5835e-01,\n",
       "            5.0887e-01, -1.1648e-01],\n",
       "          [-4.0388e-01,  4.6642e-01,  1.1231e-01,  ...,  6.7658e-01,\n",
       "            7.0514e-01, -3.9886e-01],\n",
       "          [ 8.1941e-01, -5.4786e-01, -5.1619e-02,  ...,  9.8829e-02,\n",
       "            5.9442e-01,  1.3404e+00]],\n",
       "\n",
       "         [[ 7.9032e-03,  2.9776e-02, -4.7632e-02,  ...,  8.5895e-03,\n",
       "            3.8887e-02,  4.9254e-02],\n",
       "          [-6.5967e-01,  3.0028e-01, -6.8797e-01,  ...,  3.3060e-01,\n",
       "           -1.8978e-01, -4.2268e-01],\n",
       "          [-1.1985e+00, -3.2515e-01, -5.9111e-01,  ..., -4.2985e-01,\n",
       "            9.9290e-02,  1.6690e+00],\n",
       "          [ 4.2208e-01, -6.3097e-01, -2.9648e-01,  ...,  5.5171e-01,\n",
       "            1.8846e-01,  1.1147e+00],\n",
       "          [-5.6806e-01, -1.8135e+00, -4.4668e-01,  ..., -3.4188e-03,\n",
       "            4.5228e-02, -1.0726e+00],\n",
       "          [-4.1774e-01, -1.4827e+00,  9.8313e-01,  ...,  3.5497e-01,\n",
       "            2.0233e+00, -1.5609e+00]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.9609e-02,  2.9852e-02, -1.2145e-02,  ..., -4.0618e-02,\n",
       "           -1.3418e-02,  1.8175e-02],\n",
       "          [-2.1186e-01,  2.2201e-01,  5.8752e-01,  ...,  3.7240e-01,\n",
       "            1.8293e-01,  4.6384e-01],\n",
       "          [-1.0260e+00, -1.0950e+00,  8.7973e-01,  ...,  1.2234e-01,\n",
       "            1.3336e+00, -9.9561e-01],\n",
       "          [ 1.2429e+00, -8.8135e-01, -2.8308e-01,  ...,  1.0471e+00,\n",
       "            2.9937e+00, -1.2544e-01],\n",
       "          [ 2.1240e-01, -1.9607e+00, -1.3990e+00,  ...,  1.8937e+00,\n",
       "            5.3060e-01,  7.3509e-01],\n",
       "          [-1.0975e-01, -1.1410e+00, -3.4544e-01,  ...,  6.5163e-02,\n",
       "           -5.4288e-01,  4.3925e-01]],\n",
       "\n",
       "         [[ 7.3747e-02,  2.2360e-02,  6.9325e-02,  ...,  3.9502e-02,\n",
       "            5.1242e-02,  2.2096e-02],\n",
       "          [-7.2592e-01,  9.6885e-01,  1.0027e+00,  ..., -9.7546e-01,\n",
       "            1.4039e+00, -1.9315e+00],\n",
       "          [-5.9615e-01,  1.5794e+00,  1.5836e+00,  ...,  1.4856e+00,\n",
       "            1.0993e+00,  5.1982e-01],\n",
       "          [ 9.1614e-01, -1.9039e-02, -1.3799e-01,  ...,  8.0104e-02,\n",
       "           -9.5465e-01, -1.5451e-01],\n",
       "          [-1.0649e+00, -2.0668e-01,  1.5197e+00,  ..., -9.0125e-02,\n",
       "            3.8902e-01, -4.6563e-01],\n",
       "          [-4.1051e-01, -7.6524e-01,  2.0216e+00,  ...,  9.7973e-01,\n",
       "           -4.7506e-01, -9.7310e-01]],\n",
       "\n",
       "         [[-1.2069e-01,  7.3292e-03, -6.4321e-02,  ..., -9.7469e-02,\n",
       "            7.1354e-02, -2.8533e-02],\n",
       "          [ 5.1686e-01, -2.7931e-01, -6.8866e-01,  ..., -4.3622e-01,\n",
       "           -5.4459e-01,  8.4763e-02],\n",
       "          [ 1.2073e+00,  2.0114e-01, -5.9435e-01,  ...,  1.0616e+00,\n",
       "           -1.6074e-01, -1.6744e+00],\n",
       "          [ 4.1345e-01, -6.1242e-02, -3.7587e-02,  ...,  5.4130e-01,\n",
       "           -1.6887e-01,  1.9342e-01],\n",
       "          [ 7.1947e-01, -1.7368e+00, -3.7898e-01,  ..., -6.3069e-02,\n",
       "           -3.3131e-02,  8.0648e-01],\n",
       "          [ 2.6836e-01, -1.0012e-01, -2.9034e-01,  ...,  2.1334e-01,\n",
       "           -1.7932e-01,  3.0263e-01]]]], grad_fn=<PermuteBackward0>)), (tensor([[[[-1.7249e+00, -3.1022e-01, -3.0603e-01,  ...,  1.7504e-01,\n",
       "            3.3108e-01, -4.9751e-01],\n",
       "          [-3.4926e-02, -9.5693e-02, -4.4366e-01,  ...,  1.6974e+00,\n",
       "           -7.2867e-01,  1.2075e-01],\n",
       "          [ 5.8845e-01, -5.6650e-01, -1.7187e+00,  ...,  1.3346e+00,\n",
       "           -2.5169e-01, -5.4477e-01],\n",
       "          [ 8.9678e-01, -1.2430e+00, -1.4425e+00,  ...,  1.8442e+00,\n",
       "           -3.2991e-01,  2.0485e-03],\n",
       "          [ 1.1340e+00, -7.0123e-01,  1.1950e-01,  ...,  1.1472e+00,\n",
       "           -6.7999e-01, -4.1742e-01],\n",
       "          [ 1.7202e+00,  4.6860e-02, -4.6414e-01,  ...,  1.0672e-01,\n",
       "           -2.2744e+00, -1.2240e+00]],\n",
       "\n",
       "         [[ 1.0124e-01, -9.0343e-02,  2.2931e+00,  ...,  2.3679e-01,\n",
       "            8.0488e-02, -1.9349e-01],\n",
       "          [ 7.9576e-01, -1.2118e+00, -1.1235e+00,  ...,  2.5756e-01,\n",
       "            1.0549e-01,  6.3132e-02],\n",
       "          [ 1.0634e+00, -1.7722e+00, -9.6578e-01,  ...,  4.2269e-01,\n",
       "           -2.3840e-01,  5.4256e-01],\n",
       "          [ 8.6263e-01, -1.5928e+00, -4.8899e-01,  ..., -1.3137e+00,\n",
       "           -3.0956e-01,  2.2824e-01],\n",
       "          [ 1.0839e+00, -1.3715e+00, -3.8982e-01,  ..., -9.6872e-01,\n",
       "            1.5948e+00,  6.1050e-01],\n",
       "          [ 1.0418e+00, -1.3573e+00, -1.4437e+00,  ..., -2.3456e-01,\n",
       "            9.0888e-01,  1.4739e-01]],\n",
       "\n",
       "         [[-1.8598e-01,  1.0548e+00,  4.6552e-01,  ..., -5.3790e-01,\n",
       "            3.1571e-01, -1.0873e-01],\n",
       "          [-6.6087e-01,  1.4269e-01, -1.3166e-01,  ...,  1.2832e+00,\n",
       "            9.1828e-01, -7.8358e-01],\n",
       "          [-1.1109e+00, -4.5085e-01,  3.8915e-01,  ...,  5.0454e-01,\n",
       "            5.5523e-02, -9.3808e-01],\n",
       "          [-1.4238e+00, -1.0832e+00,  1.0430e+00,  ...,  6.7556e-01,\n",
       "            1.2826e+00, -3.1142e-01],\n",
       "          [-1.4779e+00, -7.6755e-01, -7.8543e-02,  ...,  7.7274e-01,\n",
       "            1.5415e-01, -8.1619e-01],\n",
       "          [-9.6340e-01,  1.5103e+00, -1.9094e-02,  ...,  8.3554e-01,\n",
       "            1.3328e+00, -3.0148e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 5.4652e-01,  9.8054e-01, -8.6579e-01,  ..., -7.0947e-01,\n",
       "            6.9997e-01,  8.4854e-01],\n",
       "          [-9.2847e-02,  8.5818e-01, -6.8982e-01,  ..., -5.3210e-02,\n",
       "            9.6011e-04,  8.4550e-01],\n",
       "          [ 6.7975e-01,  4.6503e-01, -3.4107e-02,  ..., -3.0507e-01,\n",
       "           -8.5934e-02,  1.4059e+00],\n",
       "          [-3.0791e-01,  1.5729e+00, -2.1769e-02,  ..., -3.1004e-01,\n",
       "            8.2391e-01,  9.8439e-01],\n",
       "          [ 4.6066e-01,  1.1433e+00, -6.1274e-01,  ..., -3.6978e-01,\n",
       "            1.6092e+00, -5.2484e-01],\n",
       "          [-5.7010e-01, -2.4197e-01, -1.6958e-01,  ..., -6.3137e-02,\n",
       "            1.3082e+00,  1.1332e+00]],\n",
       "\n",
       "         [[-4.0146e-01,  3.9228e-01,  3.5569e-01,  ...,  7.0073e-01,\n",
       "            3.7821e-02, -8.2716e-02],\n",
       "          [-7.9224e-01,  1.8072e+00, -3.3172e-01,  ...,  8.4818e-01,\n",
       "           -6.1013e-01, -9.2603e-01],\n",
       "          [ 2.2135e+00,  2.0502e+00,  5.8290e-01,  ...,  1.0515e+00,\n",
       "           -1.0823e+00, -1.0787e+00],\n",
       "          [ 1.8852e-01,  1.1482e+00,  7.0164e-02,  ..., -2.9982e-01,\n",
       "           -6.7040e-01, -1.0202e+00],\n",
       "          [-2.3264e-01,  1.8689e+00, -1.0346e+00,  ...,  7.6827e-01,\n",
       "            9.3723e-01,  2.1144e-01],\n",
       "          [-1.9998e-01,  1.4474e+00, -1.3137e+00,  ..., -7.1716e-01,\n",
       "            4.3338e-01, -8.1707e-01]],\n",
       "\n",
       "         [[-7.5661e-01, -1.0617e-02,  4.4994e-01,  ..., -9.5859e-02,\n",
       "            2.4899e-02, -6.9825e-02],\n",
       "          [-1.0178e+00, -1.3348e-01,  7.8217e-01,  ..., -9.2451e-01,\n",
       "           -6.4923e-01,  5.0387e-01],\n",
       "          [-2.2168e-01, -1.3723e+00,  1.3341e+00,  ..., -7.5950e-01,\n",
       "           -2.2999e+00, -2.3732e-01],\n",
       "          [-4.8083e-01, -2.1343e-01,  1.3310e+00,  ..., -8.9777e-01,\n",
       "           -1.8699e+00, -3.1202e-01],\n",
       "          [-1.5617e+00,  2.5099e-01,  1.3530e+00,  ..., -1.0514e+00,\n",
       "           -1.3583e+00, -6.9241e-01],\n",
       "          [-6.2960e-02, -9.7893e-02,  2.2438e+00,  ...,  8.7005e-01,\n",
       "            3.3167e-01, -5.7067e-01]]]], grad_fn=<PermuteBackward0>), tensor([[[[ 9.3270e-02, -1.2455e-01, -1.7602e-01,  ..., -3.1348e-01,\n",
       "            2.5098e-01, -1.4056e-01],\n",
       "          [ 1.2060e+00,  3.1245e-01, -3.0002e-01,  ...,  3.6718e+00,\n",
       "           -2.2731e+00,  2.3750e+00],\n",
       "          [-7.8239e-01, -6.6194e-01, -3.2514e-01,  ...,  4.3229e+00,\n",
       "           -7.3491e-01, -7.7171e-01],\n",
       "          [-8.2492e-02, -1.9328e-01, -9.6427e-02,  ...,  3.4850e+00,\n",
       "           -2.4733e-02,  1.3526e+00],\n",
       "          [ 1.8830e+00, -1.8040e-01,  3.9600e-01,  ...,  2.1399e+00,\n",
       "           -1.5774e+00,  1.0118e+00],\n",
       "          [-1.8517e+00,  2.5763e-01,  1.1784e+00,  ...,  2.7812e+00,\n",
       "           -2.3093e+00, -8.8574e-01]],\n",
       "\n",
       "         [[ 1.2817e-01, -1.6043e-02,  3.0663e-02,  ..., -4.2358e-02,\n",
       "           -1.1675e-01,  1.7102e-01],\n",
       "          [ 1.2980e+00,  1.7643e-01,  5.3442e-01,  ..., -6.3708e-01,\n",
       "            2.1073e-01,  2.9605e-01],\n",
       "          [-2.2535e-01,  2.8361e+00, -1.3808e+00,  ...,  1.6576e+00,\n",
       "           -4.0341e-01, -1.4619e+00],\n",
       "          [-2.6319e+00, -1.2028e+00, -9.7343e-01,  ...,  2.0281e-01,\n",
       "           -1.1881e+00, -1.1097e+00],\n",
       "          [-5.1955e-03,  2.6217e-01,  4.9066e-01,  ..., -1.0326e-01,\n",
       "           -8.9371e-01, -8.0047e-01],\n",
       "          [-3.4269e-01,  7.2351e-01,  1.3584e+00,  ...,  2.4192e-01,\n",
       "            3.1708e-01,  1.0682e+00]],\n",
       "\n",
       "         [[ 1.0583e-02,  3.5353e-02, -5.5478e-02,  ...,  3.8392e-02,\n",
       "            3.2999e-03,  6.5741e-02],\n",
       "          [ 1.3145e+00, -6.8189e-01,  3.6391e-01,  ..., -6.3454e-01,\n",
       "           -2.6918e-01, -4.8827e-01],\n",
       "          [-7.3036e-01, -1.3107e+00, -1.1312e+00,  ..., -2.2948e-01,\n",
       "           -8.7135e-01,  4.0678e-01],\n",
       "          [ 3.3585e-01, -9.5305e-02,  2.6307e-01,  ..., -1.9251e-02,\n",
       "           -7.3608e-02,  2.4659e-01],\n",
       "          [ 2.0025e+00,  5.6909e-01,  7.2279e-01,  ..., -2.5393e+00,\n",
       "            8.5332e-02,  6.2341e-01],\n",
       "          [ 1.9383e+00, -2.0951e-01, -9.5423e-01,  ..., -1.4359e+00,\n",
       "            3.6920e-01,  2.3785e-01]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 4.9786e-03, -9.2032e-03,  7.8156e-02,  ...,  7.6930e-02,\n",
       "           -3.6026e-02,  3.9018e-02],\n",
       "          [-7.0019e-01,  7.7485e-01,  1.0363e-01,  ...,  1.8836e-01,\n",
       "           -4.3883e-01,  2.5432e-01],\n",
       "          [-1.5856e+00, -5.2110e-01, -1.2085e+00,  ...,  7.9360e-01,\n",
       "            8.2501e-01, -1.0847e+00],\n",
       "          [-1.8226e+00,  1.4013e+00,  7.9790e-01,  ..., -8.0714e-02,\n",
       "           -6.0172e-01,  5.7894e-01],\n",
       "          [-1.5025e+00, -9.4589e-01,  8.4130e-01,  ...,  1.9963e+00,\n",
       "           -1.3180e+00,  3.5581e-01],\n",
       "          [-1.3762e+00,  4.1630e-01, -1.1677e+00,  ...,  1.1389e+00,\n",
       "            1.0518e+00,  1.0597e+00]],\n",
       "\n",
       "         [[-1.9978e-01, -5.6272e-02,  7.7924e-02,  ..., -6.3649e-02,\n",
       "            5.2142e-02, -8.8874e-02],\n",
       "          [-6.4905e-01, -4.7653e-01,  1.0456e+00,  ..., -4.1554e-01,\n",
       "            6.4678e-02,  4.5299e-01],\n",
       "          [ 2.7861e-01,  1.2370e+00, -1.1043e+00,  ...,  1.7800e-01,\n",
       "           -6.8511e-01, -1.0758e+00],\n",
       "          [-1.0252e+00,  1.5038e-01,  7.1022e-01,  ...,  4.4174e-01,\n",
       "            9.8946e-01, -2.3663e-01],\n",
       "          [ 1.6333e-01, -6.8081e-01,  1.2247e-01,  ...,  4.1351e-01,\n",
       "            5.9804e-01, -5.4713e-01],\n",
       "          [-7.7785e-01,  1.7506e-01,  1.3941e+00,  ..., -5.5441e-01,\n",
       "            3.9356e-01,  2.7669e-01]],\n",
       "\n",
       "         [[ 1.0036e-01, -1.5278e-01,  1.7277e-01,  ..., -1.2451e-01,\n",
       "            1.3096e-02, -1.8016e-01],\n",
       "          [-6.9487e-01, -2.3806e-01,  3.0182e-01,  ...,  2.5629e-01,\n",
       "           -3.9038e-01,  5.6129e-01],\n",
       "          [ 7.5356e-01, -8.7507e-01,  2.7116e-01,  ...,  5.8172e-02,\n",
       "            5.2476e-01,  5.1751e-01],\n",
       "          [ 3.1106e-01,  1.1922e+00,  1.8755e+00,  ...,  7.0243e-01,\n",
       "           -5.3840e-01, -1.1631e-01],\n",
       "          [-1.6825e-01, -6.5067e-01, -3.9101e-01,  ...,  5.3691e-01,\n",
       "            2.5122e-01, -7.8723e-02],\n",
       "          [ 2.3085e-02, -4.7495e-01,  3.4144e-02,  ...,  3.6516e-01,\n",
       "           -5.1103e-01, -3.0840e-01]]]], grad_fn=<PermuteBackward0>))), hidden_states=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(input_ids = token['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5e27a6b4-b794-45c7-b494-f4099596cc46",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = Path('Data/sqaud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4fa94e05-dc6a-4cb3-adb1-7c862ed18e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Question_Answer(data_df):\n",
    "    \"\"\"\n",
    "    Convert an ordered JSON object into a token sequence\n",
    "    \"\"\"\n",
    "    Context = data_df['context']\n",
    "    Question = data_df['question']\n",
    "    Answer = data_df['answer']['text']\n",
    "    Context_Que = f\"{Context} {Question} {tokenizer.eos_token} {Answer} {tokenizer.eos_token}\"\n",
    "    Answer = f\"{Context} {Question} {tokenizer.eos_token}\"\n",
    "    return Context_Que, Answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f632a9e-6967-4bdd-9025-615a7f72a702",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(text_paths):\n",
    "    sample = []\n",
    "    for txt_file in os.listdir(text_paths):\n",
    "        if txt_file.endswith('.json'):\n",
    "            txt_path = text_paths.joinpath(txt_file)\n",
    "            sample.append({'data_path':txt_path})\n",
    "    return sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8f4ca3f8-d1d0-4ab9-9c00-ad275a136d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_path = create_dataset(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e43997b-d9fb-4171-9091-c5199c532424",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'data_path': PosixPath('Data/sqaud/Squad_data_dev_12217.json')}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_path[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbf06999-d077-47a9-b83a-9524551bf78f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('Data/sqaud/Squad_data_dev_12217.json')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txt_path[0]['data_path']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6effa06b-4fcf-47d8-ad8a-caf96ee85266",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_path = txt_path[0]['data_path']\n",
    "with open(text_path, 'r') as f:\n",
    "    json_text = json.load(f)       \n",
    "text = Question_Answer(json_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "330f1847-8568-42dc-a263-ee2021eb768c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Index_length = []\n",
    "# for idx in range(len(txt_path)):\n",
    "#         ttxt_path = txt_path[idx]['data_path']\n",
    "#         with open(ttxt_path, 'r') as f:\n",
    "#             text = json.load(f)       \n",
    "#         Context_Que, Ans = Question_Answer(text)\n",
    "#         # print(Context_Que)\n",
    "#         Ques_token = tokenizer(Context_Que, \n",
    "#                                       add_special_tokens=False,\n",
    "#                                       max_length  = 512,\n",
    "#                                       truncation=True,\n",
    "#                                       padding='max_length',\n",
    "#                                       return_tensors=\"pt\")#\n",
    "#         Ques_input_ids =   Ques_token['input_ids'].squeeze(0)   \n",
    "#         Ans_token = tokenizer(Ans, \n",
    "#                                       add_special_tokens=False,\n",
    "#                                       truncation=True,\n",
    "#                                       return_tensors=\"pt\")#\n",
    "#         Ans_input_ids =   Ans_token['input_ids'].squeeze(0)  \n",
    "#         labels = Ques_input_ids.clone()\n",
    "#         labels[: torch.nonzero(labels == tokenizer.pad_token_id).sum()] = -100 \n",
    "#         pad_tokenize = torch.nonzero(Ques_input_ids == tokenizer.eos_token)\n",
    "#         if pad_tokenize.nelement() == 0:\n",
    "#             continue\n",
    "#         length = torch.nonzero(Ques_input_ids == tokenizer.eos_token).sum()\n",
    "        \n",
    "#         # print(length)\n",
    "#         labels = Ques_input_ids[length:-1]\n",
    "#         Index_length.append(len(Ques_input_ids))\n",
    "#         # print(Ques_input_ids, labels)\n",
    "#         # break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3d7ca166-ba66-4f12-b54d-0bcf73ba9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max(Index_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "eaa5b871-5e86-4784-8c10-94466dbc7b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(Index_length, bins=100)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3859bc8-b889-45e3-b2b7-0196b17c9f6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cb13a801-8909-4ed6-a0cf-5f6cd8d5ea15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(df.shape[0]):\n",
    "#     dictionary = df.iloc[i].to_dict()\n",
    "#     data_path = path_data.joinpath(f'Truth_Data{i}.json')\n",
    "#     with open(data_path, 'w') as f:\n",
    "#         json.dump(dictionary, f)\n",
    "#     print(txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7287f433-26e1-4439-ae54-3f93ee72993d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(txt_path, 'r') as f:\n",
    "#     text = json.load(f)       \n",
    "# text = json2token(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "83a68865-b566-4d74-a38b-c76162d8d011",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "107123"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(txt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559b3646-3d91-431f-bb9b-c0cea3c34f9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a7b0fe-c100-4874-815d-d8e22824eb01",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "163bdc2c-01d4-44b9-8229-22196836d995",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FineTune_Dataset(Dataset):\n",
    "    \n",
    "    def __init__(self, sample, tokenizer, max_length=256):\n",
    "        self.sample = sample\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "        self.ignore_id = ModelArguments.pad_token\n",
    "        self.num_list = []\n",
    "        self.check()\n",
    "    def check(self):\n",
    "        for  idx in range(len(self.sample)):\n",
    "            #print(\"index : \", idx)\n",
    "            txt_path = self.sample[idx]['data_path']\n",
    "            with open(txt_path, 'r') as f:\n",
    "                text = json.load(f)       \n",
    "            Context_Que_Ans, _ = Question_Answer(text)\n",
    "            Context_Que_Ans_token = self.tokenizer(Context_Que_Ans, \n",
    "                                        add_special_tokens=False,\n",
    "                                        max_length  = self.max_length,\n",
    "                                        truncation=True,\n",
    "                                        padding='max_length',\n",
    "                                        return_tensors=\"pt\")#\n",
    "            Ques_input_ids =   Context_Que_Ans_token['input_ids'].squeeze(0)   \n",
    "            #print(\"IDS : \",Ques_input_ids)                          \n",
    "            eos_tokenize = torch.nonzero(Ques_input_ids == tokenizer.eos_token_id)\n",
    "            #print(eos_tokenize, eos_tokenize.nelement())\n",
    "            if eos_tokenize.nelement() == 2:\n",
    "                self.num_list.append(txt_path)\n",
    "\n",
    "        \n",
    "    def __getitem__(self, idx):\n",
    "        \n",
    "        txt_path = self.sample[self.num_list[idx]]['data_path']\n",
    "        with open(txt_path, 'r') as f:\n",
    "            text = json.load(f)       \n",
    "        Context_Que_Ans, Ans = Question_Answer(text)\n",
    "        Context_Que_Ans_token = self.tokenizer(Context_Que_Ans, \n",
    "                                      add_special_tokens=False,\n",
    "                                      max_length  = self.max_length,\n",
    "                                      truncation=True,\n",
    "                                      padding='max_length',\n",
    "                                      return_tensors=\"pt\")#\n",
    "        Ques_input_ids =   Context_Que_Ans_token['input_ids'].squeeze(0)                  \n",
    "        Ques_attention_ids = Context_Que_Ans_token['attention_mask'].squeeze(0)   \n",
    "        eos_tokenize = torch.nonzero(Ques_input_ids == tokenizer.eos_token_id)\n",
    "\n",
    "        labels = Ques_input_ids.clone()\n",
    "        # length = eos_tokenize[0][-1]\n",
    "        # length = torch.nonzero(Ques_input_ids == self.tokenizer.sep_token_id).sum()\n",
    "        labels[labels == self.tokenizer.pad_token_id] = self.ignore_id\n",
    "        \n",
    "        data_batch = {\"input_ids\":Ques_input_ids.to(device),'attention_mask' : Ques_attention_ids.to(device), \"labels\":labels}\n",
    "\n",
    "        return data_batch\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.num_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d265956f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_train = txt_path[:1000]\n",
    "# sample_test = txt_path[:100]\n",
    "# train_dataset = FineTune_Dataset(sample_train,tokenizer, max_length = 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a813c5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8094e7cf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b093ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea5eecf4-c006-4266-a2fa-948db84ec9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_train = txt_path[0:100000]\n",
    "sample_test = txt_path[0:1000]\n",
    "train_dataset = FineTune_Dataset(sample_train,tokenizer, max_length = 128)\n",
    "val_dataset   = FineTune_Dataset(sample_test, tokenizer, max_length = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe8e7366",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = train_dataset.num_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7cbcc5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2b4950f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_list.txt\"\n",
    "\n",
    "# Open the file in write mode ('w')\n",
    "with open(filename, 'w') as file:\n",
    "    # Iterate through each element in the list\n",
    "    for element in my_list:\n",
    "        # Write each element to the file, followed by a newline character\n",
    "        file.write(str(element) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1f8e560c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_list.txt\"\n",
    "\n",
    "# Initialize an empty list to store the elements\n",
    "my_list = []\n",
    "\n",
    "# Open the file in read mode ('r')\n",
    "with open(filename, 'r') as file:\n",
    "    # Iterate through each line in the file\n",
    "    for line in file:\n",
    "        # Convert each line (which is a string) to an integer and append it to the list\n",
    "        my_list.append(line.strip())\n",
    "\n",
    "# print(\"List loaded from file:\", my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c6fe9356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18146"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(my_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e1aae943",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "min expected at least 1 argument, got 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: min expected at least 1 argument, got 0"
     ]
    }
   ],
   "source": [
    "min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9696b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"my_list.txt\"\n",
    "\n",
    "# Open the file in write mode ('w')\n",
    "with open(filename, 'w') as file:\n",
    "    # Iterate through each element in the list\n",
    "    for element in my_list:\n",
    "        # Write each element to the file, followed by a newline character\n",
    "        file.write(str(element) + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c060ef4c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e628d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878b2363-b487-4db1-896e-0fb2f742c0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset  , batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8176b7f-b295-4533-a4f9-16cad2aff15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch_data in enumerate(val_dataset):\n",
    "    input_ids=batch_data['input_ids']\n",
    "    print(batch_data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2dc8ab2-c473-4d58-8e05-64f341d65011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cde0320-7082-4bba-896f-604e51218553",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a859fcf0-d74c-4687-b291-d01409da5abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,batch_data in enumerate(val_loader):\n",
    "    input_ids=batch_data['input_ids']\n",
    "    print(batch_data)\n",
    "    break\n",
    "print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4fad47-99d7-40a2-8ed2-d5d49ef43d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for  i,batch_data in enumerate(train_loader):\n",
    "#     input_ids=batch_data['input_ids']\n",
    "#     print(batch_data)\n",
    "#     break\n",
    "# print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1f4e32-d71f-45f6-8189-40938fc2ecb9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f178236-7803-4d0c-8048-ba6de24b050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  def accuracy_function(label, logits):\n",
    "#         masked_active_acc_one = torch.ne(label.view(-1,),ModelArguments.pad_token)\n",
    "#         masked_labels = torch.masked_select(label.view(-1), masked_active_acc_one)\n",
    "#         masked_active_acc_one = torch.unsqueeze(masked_active_acc_one, 1)\n",
    "#         masked_active_acc = masked_active_acc_one.repeat(1,logits.size(dim=2))\n",
    "#         logits = logits.view(-1,logits.size(dim=2))\n",
    "#         new_logits = logits[masked_active_acc]\n",
    "#         new_logits = new_logits.view(-1, logits.size(-1))##len(tokenizer)) #len(tokenizer)\n",
    "#         print(new_logits.size())\n",
    "#         masked_pred = torch.argmax(new_logits, dim=-1)\n",
    "#         print(masked_labels)\n",
    "#         print(masked_labels.size())\n",
    "#         result = (masked_pred == masked_labels).float().mean()\n",
    "#         return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6868a1ff-5124-473b-b57d-7a5564dbb2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for  batch_data in val_loader:\n",
    "#     input_ids=batch_data['input_ids']\n",
    "#     print(input_ids.size())\n",
    "#     print(type(input_ids), input_ids.dtype)\n",
    "#     labels=batch_data['labels']\n",
    "#     model = model.to(device)\n",
    "#     lm_logits = model(input_ids=batch_data['input_ids'], attention_mask=batch_data['attention_mask'])['logits']\n",
    "    \n",
    "#     shift_logits = lm_logits[..., :-1, :].contiguous()\n",
    "#     shift_labels = labels[..., 1:].contiguous()\n",
    "#     print(\"shift_logits >> \",shift_logits.size())\n",
    "#     print(\"shift_labels >> \",shift_labels.size())\n",
    "\n",
    "#             # Flatten the tokens\n",
    "#     loss_fct = torch.nn.CrossEntropyLoss()\n",
    "#     loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "#     print(loss)\n",
    "#     acc = accuracy_function(shift_labels, shift_logits)\n",
    "#     print(acc)\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8bd48ce-f16e-48cb-b589-2b4d341496d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1804e66d-7e77-4dd1-ae2a-29733b872c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Build_model(torch.nn.Module):    \n",
    "    def __init__(self, model):\n",
    "            super(Build_model, self).__init__()\n",
    "            self.model = model\n",
    "\n",
    "    def loss_object(self, real, pred):\n",
    "\n",
    "            loss = self.loss_fct(pred.view(-1, pred.size(-1)), real.view(-1))\n",
    "            return loss \n",
    "    def accuracy_function(self,label, logits):\n",
    "        masked_active_acc_one = torch.ne(label.view(-1,),ModelArguments.pad_token)\n",
    "        masked_labels = torch.masked_select(label.view(-1), masked_active_acc_one)\n",
    "        masked_active_acc_one = torch.unsqueeze(masked_active_acc_one, 1)\n",
    "        masked_active_acc = masked_active_acc_one.repeat(1,logits.size(dim=2))\n",
    "        logits = logits.view(-1,logits.size(dim=2))\n",
    "        new_logits = logits[masked_active_acc]\n",
    "        new_logits = new_logits.view(-1, logits.size(-1))##len(tokenizer)) #len(tokenizer)\n",
    "        masked_pred = torch.argmax(new_logits, dim=-1)\n",
    "        result = (masked_pred == masked_labels).float().mean()\n",
    "        return result\n",
    "        \n",
    " \n",
    "    def compiler(self, optimizer, loss_fct):\n",
    "        \n",
    "            self.optimizer = optimizer\n",
    "            self.loss_fct = loss_fct\n",
    "        \n",
    "    def calculate(self,\n",
    "            input_ids: Optional[torch.LongTensor] = None,\n",
    "            attention_mask: Optional[torch.LongTensor] = None,\n",
    "            labels: Optional[torch.LongTensor] = None):\n",
    "        logits = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = logits['logits']\n",
    "        new_logits = logits[..., :-1, :].contiguous()\n",
    "        new_labels = labels[..., 1:].contiguous()\n",
    "        loss = self.loss_object(new_labels, new_logits)\n",
    "        accuracy = self.accuracy_function(new_labels, new_logits)\n",
    "        return loss, accuracy             \n",
    "            \n",
    "\n",
    "    def fit(self,train_loader,val_loader,epochs):\n",
    "        history = {\n",
    "        \"epoch\": [],\n",
    "        \"loss\": [],\n",
    "        \"Accuracy\" :[],\n",
    "        \"val_loss\" :[],\n",
    "        \"val_Accuracy\" :[]\n",
    "        }\n",
    "        print(\"Training Started ........ \")\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "                    \n",
    "            total_loss = 0\n",
    "            val_loss = 0\n",
    "            total_accuracy = 0\n",
    "            val_accuracy = 0            \n",
    "            print(f\"Epoch : {epoch +1}\\n\")\n",
    "            batch =0 \n",
    "            start_iter_train = time.time()\n",
    "            for batch_data in train_loader:\n",
    "                    input_ids=batch_data['input_ids']\n",
    "                    attention_mask = batch_data['attention_mask']\n",
    "                    try:\n",
    "                        labels=batch_data['labels']\n",
    "                    except KeyError as ke:\n",
    "                        labels = None\n",
    "                    self.model.train()  # make sure we are in .train() mode    \n",
    "\n",
    "                    loss, acc = self.calculate(input_ids,attention_mask, labels)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    if (batch+1) % 100 == 0:    \n",
    "                        # self.save_weights(ModelArguments.fine_tuned_weights)\n",
    "                        print(f\"Train iter : {batch+1} ||  accuracy : {acc.detach().cpu().numpy():.4f} || loss : {loss.detach().cpu().numpy():.4f} || time : {time.time() - start_iter_train:.2f} secs\")  \n",
    "                    total_accuracy = total_accuracy+acc.detach().cpu().numpy() \n",
    "                    total_loss = total_loss + loss.detach().cpu().numpy()\n",
    "                    batch=batch+1\n",
    "\n",
    "            print(f'\\nTotal Loss: {total_loss/(batch):.4f} | Accuracy : {total_accuracy/(batch):.4f}\\n')\n",
    "            with torch.no_grad():\n",
    "                    batc =0 \n",
    "                    start_iter_val = time.time()\n",
    "                    for val_data in val_loader:\n",
    "                            input_ids=val_data['input_ids']\n",
    "                            attention_mask = val_data['attention_mask']\n",
    "                            try:\n",
    "                                labels = val_data['labels']\n",
    "                            except KeyError as ke:\n",
    "                                labels = None\n",
    "                            self.model.eval()  # make sure we are in .eval() mode\n",
    "                            loss, acc = self.calculate(input_ids,attention_mask, labels)\n",
    "                            if (batc+1) % 100 == 0:    \n",
    "                                print(f\"Validation iter : {batc+1}  ||  accuracy : {acc.detach().cpu().numpy():.4f} || loss : {loss.detach().cpu().numpy():.4f} || time : {time.time() - start_iter_val:.2f} secs\")  \n",
    "                            val_accuracy = val_accuracy+acc.detach().cpu().numpy() \n",
    "                            val_loss = val_loss + loss.detach().cpu().numpy()\n",
    "                            batc=batc+1\n",
    "\n",
    "\n",
    "            print(f'\\nTotal Validation Loss : {val_loss/(batc):.4f} | Validation Accuracy : {val_accuracy/(batc):.4f}') \n",
    "            print(f'\\nTime taken for 1 epoch : {time.time() - start:.2f} secs\\n')  \n",
    "        return history \n",
    "    def save_weights(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    def load_weights(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "    def predict(self, inp, MAX_LEN=10):\n",
    "        with torch.no_grad():\n",
    "                    input_ids=inp['input_ids']\n",
    "                    self.model.eval()\n",
    "                    outputs =  model.generate(input_ids = input_ids, max_new_tokens = MAX_LEN)\n",
    "                    out = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "                    # output =  self.model(input_ids=input_ids)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e6aca4d-f361-466e-876c-2ccc4d93b100",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "loss_fct = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=ModelArguments.INIT_LR)      \n",
    "        \n",
    "model = model.to(device)\n",
    "GPTmodel = Build_model(model)\n",
    "GPTmodel.compiler(optimizer, loss_fct)\n",
    "# GPTmodel.load_weights(ModelArguments.fine_tuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3dbf27-99d6-4ca8-b133-25c94e3c535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"##### Model Start training .....\")\n",
    "history = GPTmodel.fit(train_loader,val_loader, epochs=ModelArguments.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa53110f-891f-4b84-b14c-de62ab2819b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(\"Where did fortune cookies originate?\", return_tensors=\"pt\")\n",
    "token = {key:value.to(device) for key, value in token.items()}\n",
    "\n",
    "out = GPTmodel.predict(token, MAX_LEN=50)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19860546-d4e7-491b-8a65-8b70edfaf5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPTmodel.save_weights(ModelArguments.fine_tuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b20fd117-fcce-4e12-9caa-f5badebe17fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a2aa0-b1b6-4311-9dfb-a616ffa47f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "GPTmodel_Test = Build_model(model)\n",
    "GPTmodel_Test.load_weights(ModelArguments.fine_tuned_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a4b510d-aaba-4b17-9f1f-ac8cf69ae5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = tokenizer(\"What is insurance\", return_tensors=\"pt\")\n",
    "out = GPTmodel_Test.predict(token, MAX_LEN=50)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20069051-17ae-486b-bebf-a0d4eaa043ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167c8049-dd3c-493d-9cb7-a7e00f6a41e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e1291a-3837-43c9-b88b-eec44177f347",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = torch.randn(10)\n",
    "input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8ffcca0-a363-4341-8368-c0aee1950f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "padding = (0,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d310226-35dd-4848-bb08-b8b3b8a2f82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.nn.functional.pad(input, padding, mode = \"constant\", value = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4025752-b02f-4d2f-94ce-d40bb9458a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "m(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2faa7f31-20eb-4d41-a60e-e62c516b8c40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup GPU/CPU\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# move model over to detected device\n",
    "# model.to(device)\n",
    "# # activate training mode of model\n",
    "# model.train()\n",
    "# initialize adam optimizer with weight decay (reduces chance of overfitting)\n",
    "optim = AdamW(model.parameters(), lr=1e-5)\n",
    "#optim = torch.optim.Adam(model.parameters(), lr=1e-5)\n",
    "\n",
    "# initialize data loader for training data\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1aecbf-62b6-4c42-9c2a-3bbe79ab635f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for batch in train_loader:\n",
    "#     print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfd83436-8893-4e57-a545-0775ddc55dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Build_model(torch.nn.Module):    \n",
    "    def __init__(self, model):\n",
    "            super(Build_model, self).__init__()\n",
    "            self.model = model\n",
    "\n",
    "    def loss_object(self, real, pred):\n",
    "\n",
    "            loss = self.loss_fct(pred.view(-1, pred.size(-1)), real.view(-1))\n",
    "            return loss \n",
    "    def accuracy_function(self,label, logits):\n",
    "        masked_active_acc_one = torch.ne(label.view(-1,),ModelArguments.pad_token)\n",
    "        masked_labels = torch.masked_select(label.view(-1), masked_active_acc_one)\n",
    "        masked_active_acc_one = torch.unsqueeze(masked_active_acc_one, 1)\n",
    "        masked_active_acc = masked_active_acc_one.repeat(1,logits.size(dim=2))\n",
    "        logits = logits.view(-1,logits.size(dim=2))\n",
    "        new_logits = logits[masked_active_acc]\n",
    "        new_logits = new_logits.view(-1, logits.size(-1))##len(tokenizer)) #len(tokenizer)\n",
    "        masked_pred = torch.argmax(new_logits, dim=-1)\n",
    "        result = (masked_pred == masked_labels).float().mean()\n",
    "        return result\n",
    "        \n",
    " \n",
    "    def compiler(self, optimizer, loss_fct):\n",
    "        \n",
    "            self.optimizer = optimizer\n",
    "            self.loss_fct = loss_fct\n",
    "        \n",
    "    def calculate(self,\n",
    "            input_ids: Optional[torch.LongTensor] = None,\n",
    "            labels: Optional[torch.LongTensor] = None):\n",
    "\n",
    "        logits = self.model(input_ids=input_ids)['logits']\n",
    "        if labels == None:\n",
    "                labels = input_ids_x.clone()\n",
    "                labels[labels == tokenizer.pad_token_id] = self.ignore_id\n",
    "                new_logits = logits[..., :-1, :].contiguous()\n",
    "                new_labels = label[..., 1:].contiguous()\n",
    "                loss = self.loss_object(new_labels, new_logits)\n",
    "                accuracy = self.accuracy_function(new_labels, new_logits)\n",
    "        else :\n",
    "            \n",
    "                loss = self.loss_object(labels, logits)\n",
    "                accuracy = self.accuracy_function(labels, logits)\n",
    "        return loss, accuracy             \n",
    "            \n",
    "\n",
    "    def fit(self,train_dataset,val_dataset,epochs):\n",
    "        history = {\n",
    "        \"epoch\": [],\n",
    "        \"loss\": [],\n",
    "        \"Accuracy\" :[],\n",
    "        \"val_loss\" :[],\n",
    "        \"val_Accuracy\" :[]\n",
    "        }\n",
    "        print(\"Training Started ........ \")\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "                    \n",
    "            total_loss = 0\n",
    "            val_loss = 0\n",
    "            total_accuracy = 0\n",
    "            val_accuracy = 0            \n",
    "            print(f\"Epoch : {epoch +1}\\n\")\n",
    "            batch =0 \n",
    "            start_iter_train = time.time()\n",
    "            for batch_data in train_dataset:\n",
    "                    input_ids=batch_data['input_ids']\n",
    "                    labels=batch_data['labels']\n",
    "                    self.model.train()  # make sure we are in .train() mode    \n",
    "\n",
    "                    loss, acc = self.calculate(input_ids, labels)\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    if (batch+1) % 1 == 0:    \n",
    "                        # self.save_weights(ModelArguments.fine_tuned_weights)\n",
    "                        print(f\"Train iter : {batch+1} ||  accuracy : {acc.detach().cpu().numpy():.4f} || loss : {loss.detach().cpu().numpy():.4f} || time : {time.time() - start_iter_train:.2f} secs\")  \n",
    "                    total_accuracy = total_accuracy+acc.detach().cpu().numpy() \n",
    "                    total_loss = total_loss + loss.detach().cpu().numpy()\n",
    "                    batch=batch+1\n",
    "\n",
    "            print(f'\\nTotal Loss: {total_loss/(batch):.4f} | Accuracy : {total_accuracy/(batch):.4f}\\n')\n",
    "            with torch.no_grad():\n",
    "                    batc =0 \n",
    "                    start_iter_val = time.time()\n",
    "                    for val_data in val_dataset:\n",
    "                            input_ids=val_data['input_ids']\n",
    "                            labels = val_data['labels']\n",
    "                            self.model.eval()  # make sure we are in .eval() mode\n",
    "                            loss, acc = self.calculate(input_ids, labels)\n",
    "                            if (batc+1) % 1 == 0:    \n",
    "                                print(f\"Validation iter : {batc+1}  ||  accuracy : {acc.detach().cpu().numpy():.4f} || loss : {loss.detach().cpu().numpy():.4f} || time : {time.time() - start_iter_val:.2f} secs\")  \n",
    "                            val_accuracy = val_accuracy+acc.detach().cpu().numpy() \n",
    "                            val_loss = val_loss + loss.detach().cpu().numpy()\n",
    "                            batc=batc+1\n",
    "\n",
    "\n",
    "            print(f'\\nTotal Validation Loss : {val_loss/(batc):.4f} | Validation Accuracy : {val_accuracy/(batc):.4f}') \n",
    "            print(f'\\nTime taken for 1 epoch : {time.time() - start:.2f} secs\\n')  \n",
    "        return history \n",
    "    def save_weights(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    def load_weights(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "    def predict(self, inp, MAX_LEN=10):\n",
    "        with torch.no_grad():\n",
    "                    input_ids=inp['input_ids']\n",
    "                    self.model.eval()\n",
    "                    outputs =  model.generate(input_ids = input_ids, max_new_tokens = MAX_LEN)\n",
    "                    out = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "                    # output =  self.model(input_ids=input_ids)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d9f31bb-0ba7-49e7-b3c7-a46de6564f1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b52f1-6327-419c-89be-a40d77384454",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e53fd184-8bac-42b1-afb2-386abbae35b3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5315c0b8-c859-4a94-b1c0-1c0ee80eb46c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "579694c2-56f6-42a5-9bbc-d6c3e78e2ac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Build_model(torch.nn.Module):    \n",
    "    def __init__(self, model):\n",
    "            super(Build_model, self).__init__()\n",
    "            self.model = model\n",
    "\n",
    "    def loss_object(self, real, pred):\n",
    "\n",
    "            loss = self.loss_fct(pred.view(-1, pred.size(-1)), real.view(-1))\n",
    "            return loss \n",
    "    def accuracy_function(self,label, logits):\n",
    "        masked_active_acc_one = torch.ne(label.view(-1,),ModelArguments.pad_token)\n",
    "        masked_labels = torch.masked_select(label.view(-1), masked_active_acc_one)\n",
    "        masked_active_acc_one = torch.unsqueeze(masked_active_acc_one, 1)\n",
    "        masked_active_acc = masked_active_acc_one.repeat(1,logits.size(dim=2))\n",
    "        logits = logits.view(-1,logits.size(dim=2))\n",
    "        new_logits = logits[masked_active_acc]\n",
    "        new_logits = new_logits.view(-1, logits.size(-1))##len(tokenizer)) #len(tokenizer)\n",
    "        masked_pred = torch.argmax(new_logits, dim=-1)\n",
    "        result = (masked_pred == masked_labels).float().mean()\n",
    "        return result\n",
    "        \n",
    " \n",
    "    def compiler(self, optimizer, loss_fct):\n",
    "        \n",
    "            self.optimizer = optimizer\n",
    "            self.loss_fct = loss_fct\n",
    "\n",
    "    def fit(self,train_dataset,val_dataset,epochs):\n",
    "        history = {\n",
    "        \"epoch\": [],\n",
    "        \"loss\": [],\n",
    "        \"Accuracy\" :[],\n",
    "        \"val_loss\" :[],\n",
    "        \"val_Accuracy\" :[]\n",
    "        }\n",
    "        print(\"Training Started ........ \")\n",
    "        for epoch in range(epochs):\n",
    "            start = time.time()\n",
    "                    \n",
    "            total_loss = 0\n",
    "            val_loss = 0\n",
    "            total_accuracy = 0\n",
    "            val_accuracy = 0            \n",
    "            print(f\"Epoch : {epoch +1}\\n\")\n",
    "            batch =0 \n",
    "            start_iter_train = time.time()\n",
    "            for batch_data in train_dataset:\n",
    "                    input_ids=batch_data['input_ids']\n",
    "                    label=batch_data['labels']\n",
    "                    self.model.train()  # make sure we are in .train() mode                \n",
    "                    logits = self.model(input_ids=input_ids)['logits']\n",
    "                    new_logits = logits[..., :-1, :].contiguous()\n",
    "                    new_labels = label[..., 1:].contiguous()\n",
    "                    loss = self.loss_object(new_labels, new_logits)\n",
    "\n",
    "                    self.optimizer.zero_grad()\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "                    acc = self.accuracy_function(new_labels, new_logits)\n",
    "                    if (batch+1) % 1 == 0:    \n",
    "                        print(f\"Train iter : {batch+1} ||  accuracy : {acc.detach().cpu().numpy():.4f} || loss : {loss.detach().cpu().numpy():.4f} || time : {time.time() - start_iter_train:.2f} secs\")  \n",
    "                    total_accuracy = total_accuracy+acc.detach().cpu().numpy() \n",
    "                    total_loss = total_loss + loss.detach().cpu().numpy()\n",
    "                    batch=batch+1\n",
    "\n",
    "            print(f'\\nTotal Loss: {total_loss/(batch):.4f} | Accuracy : {total_accuracy/(batch):.4f}\\n')\n",
    "            with torch.no_grad():\n",
    "                    batc =0 \n",
    "                    start_iter_val = time.time()\n",
    "                    for val_data in val_dataset:\n",
    "                            input_ids=val_data['input_ids']\n",
    "                            label = val_data['labels']\n",
    "                            self.model.eval()  # make sure we are in .eval() mode\n",
    "                            logits = self.model(input_ids=input_ids)['logits']\n",
    "                            shift_logits = logits[..., :-1, :].contiguous()\n",
    "                            shift_labels = label[..., 1:].contiguous()\n",
    "                        \n",
    "                            loss = self.loss_object(shift_labels, shift_logits)\n",
    "                            acc = self.accuracy_function(shift_labels, shift_logits)\n",
    "                            if (batc+1) % 1 == 0:    \n",
    "                                print(f\"Validation iter : {batc+1}  ||  accuracy : {acc.detach().cpu().numpy():.4f} || loss : {loss.detach().cpu().numpy():.4f} || time : {time.time() - start_iter_val:.2f} secs\")  \n",
    "                            val_accuracy = val_accuracy+acc.detach().cpu().numpy() \n",
    "                            val_loss = val_loss + loss.detach().cpu().numpy()\n",
    "                            batc=batc+1\n",
    "\n",
    "\n",
    "            print(f'\\nTotal Validation Loss : {val_loss/(batc):.4f} | Validation Accuracy : {val_accuracy/(batc):.4f}') \n",
    "            print(f'\\nTime taken for 1 epoch : {time.time() - start:.2f} secs\\n')  \n",
    "        return history \n",
    "    def save_weights(self, path):\n",
    "        torch.save(self.model.state_dict(), path)\n",
    "    def load_weights(self, path):\n",
    "        self.model.load_state_dict(torch.load(path))\n",
    "    def predict(self, inp, MAX_LEN=10):\n",
    "        with torch.no_grad():\n",
    "                    input_ids=inp['input_ids']\n",
    "                    self.model.eval()\n",
    "                    outputs =  model.generate(input_ids = input_ids, max_new_tokens = MAX_LEN)\n",
    "                    out = tokenizer.decode(outputs[0], skip_special_tokens = True)\n",
    "                    # output =  self.model(input_ids=input_ids)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
